{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 4.3 - Chatbot to detect emotions\n",
    "\n",
    "Copyright, Vrije Universiteit Amsterdam, Faculty of Humanities, CLTL\n",
    "\n",
    "In this notebook, we will create a Telegram chatbot that will answer questions, given a predefined question-answer set. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Main goal of this notebook**: The most important goal of this notebook is to have a Telegram chatbot that you can ask factual questions to, and receive predefined answers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**At the end of this notebook, you will**:\n",
    "* **Use a predefined question - answering dataset**: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using a question-answer dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import nltk\n",
    "import random\n",
    "import pickle\n",
    "import datetime\n",
    "import requests\n",
    "from pprint import PrettyPrinter\n",
    "from gensim.models import KeyedVectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_token():\n",
    "    tokens_path = './data/tokens.json'\n",
    "    with open(tokens_path) as f:\n",
    "        tokens = json.load(f)\n",
    "\n",
    "    return tokens['CLTL_token']\n",
    "\n",
    "def read_qa():\n",
    "    qa_path = './data/emotions.json'\n",
    "    with open(qa_path) as f:\n",
    "        qa_data = json.load(f)\n",
    "\n",
    "    return qa_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BotHandler:\n",
    "    def __init__(self, token):\n",
    "        self.token = token\n",
    "        self.api_url = \"https://api.telegram.org/bot{}/\".format(token)\n",
    "\n",
    "    def get_all_messages(self, offset=None, timeout=200):\n",
    "        \"\"\" Function to get all messages sent to the bot \"\"\"\n",
    "        method = 'getUpdates'\n",
    "        params = {'timeout': timeout, 'offset': offset}\n",
    "        resp = requests.get(self.api_url + method, params)\n",
    "        \n",
    "        return resp.json()['result']\n",
    "    \n",
    "    def filter_messages_by(self, update, chat_id):\n",
    "        \"\"\" Function to filter messages by user id\"\"\"\n",
    "        return 'message' in update.keys() and update['message']['chat']['id'] == chat_id\n",
    "\n",
    "    def get_last_message_by(self, chat_id):\n",
    "        \"\"\" Function to get the last message sent to the bot by a specific user\"\"\"\n",
    "        messages = self.get_all_messages()\n",
    "        messages_by_user = list(filter(lambda m: self.filter_messages_by(m, chat_id), messages))\n",
    "\n",
    "        last_message = None\n",
    "        if messages_by_user and 'message' in messages_by_user[-1].keys():\n",
    "            last_message = messages_by_user[-1]['message']['text']\n",
    "\n",
    "        return last_message\n",
    "    \n",
    "    def send_message_to(self, chat_id, text):\n",
    "        \"\"\" Function to send a message from the bot to a specific user\"\"\"\n",
    "        params = {'chat_id': chat_id, 'text': text}\n",
    "        method = 'sendMessage'\n",
    "        resp = requests.post(self.api_url + method, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_emotion(chat, vectorizer, transformer, classifier, label_encoder):\n",
    "    counts = vectorizer.transform(chat)\n",
    "    tfidf = transformer.transform(counts)\n",
    "    predictions = classifier.predict(tfidf)\n",
    "\n",
    "    for review, predicted_label in zip(chat, predictions):\n",
    "        predicted_emotion = label_encoder.classes_[predicted_label]\n",
    "        \n",
    "    return predicted_emotion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_similar_words(embedding_model, message):\n",
    "    # TODO filte rby content words\n",
    "    words = nltk.tokenize.word_tokenize(message)\n",
    "    \n",
    "    similar_words = []\n",
    "    for word in words:\n",
    "        try:\n",
    "            word_neighborhood = embedding_model.most_similar(positive=[word], topn=10)\n",
    "            word_neighborhood = [item[0].lower() for item in word_neighborhood]\n",
    "        except KeyError as e:\n",
    "            print(\"word '%s' not in embedding vocabulary\" % word)\n",
    "            \n",
    "        similar_words.extend(word_neighborhood)\n",
    "    \n",
    "    return similar_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_response(message, qa_data, vectorizer, transformer, classifier, label_encoder, embedding_model):\n",
    "    response = \"I cannot respond to this\"\n",
    "    emotion = classify_emotion([message], vectorizer, transformer, classifier, label_encoder)\n",
    "    similar_words = get_similar_words(embedding_model, message)\n",
    "    # PrettyPrinter(indent=4).pprint(similar_words)\n",
    "    \n",
    "    for i in qa_data['intents']:\n",
    "        if emotion == i['category']:\n",
    "            print(\"Emotion detected: {emotion}\".format(emotion=emotion))\n",
    "            word_intersection = list(set(i['questions']) & set(similar_words))\n",
    "\n",
    "            if word_intersection:\n",
    "                # TODO interpretability: keyword retrieval due to ...\n",
    "                print(\"Keywords detected: {intersection}\".format(intersection=word_intersection))\n",
    "                response = random.choice(i['responses'])\n",
    "                break\n",
    "    \n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_embeddings():\n",
    "    path_to_model = '/Users/selbaez/Documents/PhD/CLTL/data/word_embeddings/GoogleNews-vectors-negative300.bin'\n",
    "    embedding_model = KeyedVectors.load_word2vec_format(path_to_model, binary=True)\n",
    "    \n",
    "    return embedding_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_models():\n",
    "    filename_vectorizer = '../lab3.machine_learning/models/utterance_vec.sav'\n",
    "    filename_transformer = '../lab3.machine_learning/models/utterance_transf.sav'\n",
    "    filename_encoder = '../lab3.machine_learning/models/label_encoder.sav'\n",
    "    filename_classifier = '../lab3.machine_learning/models/svm_linear_clf_bow.sav'\n",
    "\n",
    "    # load the classifier and the vectorizer from disk\n",
    "    loaded_classifier = pickle.load(open(filename_classifier, 'rb'))\n",
    "    loaded_vectorizer = pickle.load(open(filename_vectorizer, 'rb'))\n",
    "    loaded_transformer = pickle.load(open(filename_transformer, 'rb'))\n",
    "    loaded_label_encoder = pickle.load(open(filename_encoder, 'rb'))\n",
    "    \n",
    "    return loaded_vectorizer, loaded_transformer, loaded_classifier, loaded_label_encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLTL_TOKEN = read_token()\n",
    "user_id = 408043639\n",
    "\n",
    "qa_data = read_qa()\n",
    "vectorizer, transformer, classifier, label_encoder = load_models()\n",
    "embedding_model = load_embeddings()\n",
    "bot = BotHandler(CLTL_TOKEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word 'of' not in embedding vocabulary\n",
      "Emotion detected: neutral\n",
      "Emotion detected: neutral\n",
      "Keywords detected: ['music']\n",
      "Received: I hate hip hop music because of the beats that are too much for me\n",
      "Responded: That music is fine\n"
     ]
    }
   ],
   "source": [
    "last_message = bot.get_last_message_by(user_id)\n",
    "response = create_response(last_message, qa_data, vectorizer, transformer, classifier, label_encoder, embedding_model)\n",
    "bot.send_message_to(user_id, response)\n",
    "\n",
    "\n",
    "print(\"Received: {message}\".format(message=last_message))\n",
    "print(\"Responded: {response}\".format(response=response))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## End of this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}