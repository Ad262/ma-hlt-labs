{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 4.3 - Chatbot to detect emotions\n",
    "\n",
    "Copyright, Vrije Universiteit Amsterdam, Faculty of Humanities, CLTL\n",
    "\n",
    "In this notebook, we will create a Telegram chatbot that will answer questions, given a predefined question-answer set. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Main goal of this notebook**: The most important goal of this notebook is to have a Telegram chatbot that you can ask factual questions to, and receive predefined answers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**At the end of this notebook, you will**:\n",
    "* **Use a predefined question - answering dataset**: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using a question-answer dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import random\n",
    "import pickle\n",
    "import datetime\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_token():\n",
    "    tokens_path = './data/tokens.json'\n",
    "    with open(tokens_path) as f:\n",
    "        tokens = json.load(f)\n",
    "\n",
    "    return tokens['CLTL_token']\n",
    "\n",
    "def read_qa():\n",
    "    qa_path = './data/emotions.json'\n",
    "    with open(qa_path) as f:\n",
    "        qa_data = json.load(f)\n",
    "\n",
    "    return qa_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BotHandler:\n",
    "    def __init__(self, token):\n",
    "        self.token = token\n",
    "        self.api_url = \"https://api.telegram.org/bot{}/\".format(token)\n",
    "\n",
    "    def get_all_messages(self, offset=None, timeout=200):\n",
    "        \"\"\" Function to get all messages sent to the bot \"\"\"\n",
    "        method = 'getUpdates'\n",
    "        params = {'timeout': timeout, 'offset': offset}\n",
    "        resp = requests.get(self.api_url + method, params)\n",
    "        return resp.json()['result']\n",
    "\n",
    "    def get_last_message_by(self, chat_id):\n",
    "        \"\"\" Function to get the last message sent to the bot by a specific user\"\"\"\n",
    "        messages = self.get_all_messages()\n",
    "        messages_by_user = list(filter(lambda d: d['message']['chat']['id'] == chat_id, messages))\n",
    "\n",
    "        if messages_by_user:\n",
    "            last_message = messages_by_user[-1]['message']['text']\n",
    "        else:\n",
    "            last_message = None\n",
    "\n",
    "        return last_message\n",
    "    \n",
    "    def send_message_to(self, chat_id, text):\n",
    "        \"\"\" Function to send a message from the bot to a specific user\"\"\"\n",
    "        params = {'chat_id': chat_id, 'text': text}\n",
    "        method = 'sendMessage'\n",
    "        resp = requests.post(self.api_url + method, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_emotion(chat, vectorizer, transformer, classifier, label_encoder):\n",
    "    counts = vectorizer.transform(chat)\n",
    "    tfidf = transformer.transform(counts)\n",
    "    predictions = classifier.predict(tfidf)\n",
    "\n",
    "    for review, predicted_label in zip(chat, predictions):\n",
    "        predicted_emotion = label_encoder.classes_[predicted_label]\n",
    "        \n",
    "    return predicted_emotion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_response(message, qa_data, vectorizer, transformer, classifier, label_encoder):\n",
    "    response = \"I cannot respond to this\"\n",
    "    message = [message]\n",
    "    emotion = classify_emotion(message, vectorizer, transformer, classifier, label_encoder)\n",
    "    \n",
    "    for i in qa_data['intents']:\n",
    "        if emotion == i['category']:\n",
    "            print(\"Emotion detected: {emotion}\".format(emotion=emotion))\n",
    "            response = random.choice(i['responses'])\n",
    "            break\n",
    "    \n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_models():\n",
    "    filename_vectorizer = '../lab3.machine_learning/models/utterance_vec.sav'\n",
    "    filename_transformer = '../lab3.machine_learning/models/utterance_transf.sav'\n",
    "    filename_encoder = '../lab3.machine_learning/models/label_encoder.sav'\n",
    "    filename_classifier = '../lab3.machine_learning/models/svm_linear_clf_bow.sav'\n",
    "\n",
    "    # load the classifier and the vectorizer from disk\n",
    "    loaded_classifier = pickle.load(open(filename_classifier, 'rb'))\n",
    "    loaded_vectorizer = pickle.load(open(filename_vectorizer, 'rb'))\n",
    "    loaded_transformer = pickle.load(open(filename_transformer, 'rb'))\n",
    "    loaded_label_encoder = pickle.load(open(filename_encoder, 'rb'))\n",
    "    \n",
    "    return loaded_vectorizer, loaded_transformer, loaded_classifier, loaded_label_encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLTL_TOKEN = read_token()\n",
    "user_id = 408043639\n",
    "\n",
    "qa_data = read_qa()\n",
    "vectorizer, transformer, classifier, label_encoder = load_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Emotion detected: joy\n",
      "Received: You are so funny\n",
      "Responded: That's great!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/envs/ma-hlt-labs/lib/python3.8/site-packages/sklearn/feature_extraction/text.py:383: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens [\"'d\", \"'ll\", \"'re\", \"'s\", \"'ve\", 'could', 'might', 'must', \"n't\", 'need', 'sha', 'wo', 'would'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n"
     ]
    }
   ],
   "source": [
    "bot = BotHandler(CLTL_TOKEN)\n",
    "last_message = bot.get_last_message_by(user_id)\n",
    "response = create_response(last_message, qa_data, vectorizer, transformer, classifier, label_encoder)\n",
    "bot.send_message_to(user_id, response)\n",
    "\n",
    "\n",
    "print(\"Received: {message}\".format(message=last_message))\n",
    "print(\"Responded: {response}\".format(response=response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## End of this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
