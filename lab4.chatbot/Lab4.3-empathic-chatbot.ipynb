{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 4.3 - Chatbot to detect emotions\n",
    "\n",
    "Copyright, Vrije Universiteit Amsterdam, Faculty of Humanities, CLTL\n",
    "\n",
    "In this notebook, we will create a Telegram chatbot that will adetect the emotion in a message, and respond appropriately according to a set of keywords."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Main goal of this notebook**: The most important goal of this notebook is to have a Telegram chatbot that can detect emotion, and detect keywords in the received messages."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**At the end of this notebook, you will**:\n",
    "* **Integrate knowledge you have learned in the previous labs such as**:\n",
    "  * **Load a pre-trained emotion classifier**\n",
    "  * **Measure semantic similarity between a set of words**\n",
    "  * **Use a predefined question - answering dataset**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating an empathic semantic chatbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "import random\n",
    "import pickle\n",
    "from pprint import PrettyPrinter\n",
    "from collections import defaultdict\n",
    "from gensim.models import KeyedVectors\n",
    "\n",
    "from utils import read_token, read_qa, BotHandler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading pretrained models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we will load the pre-trained models we have: the emotion classifier and the word embedding model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def load_models():\n",
    "    filename_vectorizer = '../lab3.machine_learning/models/utterance_vec.sav'\n",
    "    filename_transformer = '../lab3.machine_learning/models/utterance_transf.sav'\n",
    "    filename_encoder = '../lab3.machine_learning/models/label_encoder.sav'\n",
    "    filename_classifier = '../lab3.machine_learning/models/svm_linear_clf_bow.sav'\n",
    "\n",
    "    # load the classifier and the vectorizer from disk\n",
    "    loaded_classifier = pickle.load(open(filename_classifier, 'rb'))\n",
    "    loaded_vectorizer = pickle.load(open(filename_vectorizer, 'rb'))\n",
    "    loaded_transformer = pickle.load(open(filename_transformer, 'rb'))\n",
    "    loaded_label_encoder = pickle.load(open(filename_encoder, 'rb'))\n",
    "\n",
    "    return loaded_vectorizer, loaded_transformer, loaded_classifier, loaded_label_encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def load_embeddings():\n",
    "    path_to_model = '/Users/selbaez/Documents/PhD/CLTL/data/word_embeddings/GoogleNews-vectors-negative300.bin'\n",
    "    embedding_model = KeyedVectors.load_word2vec_format(path_to_model, binary=True)\n",
    "\n",
    "    return embedding_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classifying emotions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also have to define the funtions to classify the emotion and to get similar words. To classify the emotion in the message we will need the message and the classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def classify_emotion(message, vectorizer, transformer, classifier, label_encoder):\n",
    "    # Remember our classifier expects a list of texts\n",
    "    message = [message]\n",
    "\n",
    "    counts = vectorizer.transform(message)\n",
    "    tfidf = transformer.transform(counts)\n",
    "    predictions = classifier.predict(tfidf)\n",
    "\n",
    "    for predicted_label in predictions:\n",
    "        predicted_emotion = label_encoder.classes_[predicted_label]\n",
    "\n",
    "    return predicted_emotion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detecting keywords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have to define the function by which we will try to match the topic keywords (e.g. music) to the tokens found in the message. First we will have to expand the meaning of the message by finding similar words to the ones the user sent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def get_similar_words(embedding_model, message, num_similar_words=10, verbose=False):\n",
    "    # TODO filter by content words\n",
    "    tokens = nltk.tokenize.word_tokenize(message)\n",
    "\n",
    "    similar_words = defaultdict(list)\n",
    "    for token in set(tokens):\n",
    "        try:\n",
    "            word_neighborhood = embedding_model.most_similar(positive=[token], topn=num_similar_words)\n",
    "            for item in word_neighborhood:\n",
    "                word = item[0].lower()\n",
    "                similar_words[word].append(token)\n",
    "\n",
    "        except KeyError as e:\n",
    "            print(\"token '%s' not in embedding vocabulary\" % token)\n",
    "\n",
    "    if verbose:\n",
    "        PrettyPrinter(indent=2).pprint(similar_words)\n",
    "\n",
    "    return similar_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we can find the intersection between our enriched message tokens and the pre-defined keywords in our qa dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def get_keyword_intersection(questions, similar_words):\n",
    "    message_words = similar_words.keys()\n",
    "\n",
    "    word_intersection = list(set(questions) & set(message_words))\n",
    "\n",
    "    matched_words = {w: similar_words[w] for w in word_intersection}\n",
    "\n",
    "    return matched_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last thing we need to do is create a response, given an incoming message. Here we can call the functions we defined before to classify emotion, enrich the meaning of the message, and match keywords."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def create_response(message, qa_data, vectorizer, transformer, classifier, label_encoder, embedding_model):\n",
    "    response = \"I cannot respond to this\"\n",
    "    emotion = classify_emotion(message, vectorizer, transformer, classifier, label_encoder)\n",
    "    similar_words = get_similar_words(embedding_model, message)\n",
    "\n",
    "    for i in qa_data['intents']:\n",
    "        if emotion == i['category']:\n",
    "            word_intersection = get_keyword_intersection(i['questions'], similar_words)\n",
    "\n",
    "            if word_intersection:\n",
    "                print(\"Emotion detected: {emotion}\".format(emotion=emotion))\n",
    "                print(\"Keywords detected [(keyword): (message_token)]: \\n\\t{intersection}\".format(intersection=word_intersection))\n",
    "\n",
    "                response = random.choice(i['responses'])\n",
    "                break\n",
    "\n",
    "    return response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try it out!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As in previous notebooks, we create out BotHandler and respond to the last message sent to the Telegram chatbot by a specific user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "CLTL_TOKEN = read_token()\n",
    "user_id = 408043639\n",
    "\n",
    "qa_data = read_qa(qa_path = './data/emotions.json')\n",
    "vectorizer, transformer, classifier, label_encoder = load_models()\n",
    "embedding_model = load_embeddings()\n",
    "bot = BotHandler(CLTL_TOKEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/envs/ma-hlt-labs/lib/python3.8/site-packages/sklearn/feature_extraction/text.py:383: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens [\"'d\", \"'ll\", \"'re\", \"'s\", \"'ve\", 'could', 'might', 'must', \"n't\", 'need', 'sha', 'wo', 'would'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Emotion detected: neutral\n",
      "Keywords detected [(keyword): (message_token)]: \n",
      "\t{'song': ['lyrics', 'songs'], 'melody': ['lyrics']}\n",
      "Received: lyrics in their songs\n",
      "Responded: That music is fine\n"
     ]
    }
   ],
   "source": [
    "last_message = bot.get_last_message_by(user_id)\n",
    "response = create_response(last_message, qa_data, vectorizer, transformer, classifier, label_encoder, embedding_model)\n",
    "bot.send_message_to(user_id, response)\n",
    "\n",
    "\n",
    "print(\"Received: {message}\".format(message=last_message))\n",
    "print(\"Responded: {response}\".format(response=response))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## End of this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
