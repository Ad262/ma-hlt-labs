{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook for simple text classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we are going to build a classifier for detecting offensive language. We are going to use the data set that is provided by the SemEval-2019 task Offenseval: https://competitions.codalab.org/competitions/20011. SemEval tasks are academic competitions in which the organizers challenge research teams to solve a shared task. The results of all teams are published and the participants are requested to submit a paper describing their system. In the case of Offenseval, there were three subtasks:\n",
    "\n",
    "- decide whether a tweet is offensive or not (subtask_a)\n",
    "- decide what is the type of offense: targeted or untargeted (subtask_b)\n",
    "- decide what is the type of target: individual, group, other (subtask_c)\n",
    "\n",
    "More information can be found here:\n",
    "\n",
    "- Marcos Zampieri, Shervin Malmasi, Preslav Nakov, Sara Rosenthal, Noura Farra, Ritesh Kumar (2019). SemEval-2019 Task 6: Identifying and Categorizing Offensive Language in Social Media (OffensEval), https://www.aclweb.org/anthology/S19-2010, https://arxiv.org/abs/1903.08983\n",
    "- Offensive Language Identification Dataset - OLID: https://scholar.harvard.edu/malmasi/olid\n",
    "\n",
    "At the end of this notebook, you learned:\n",
    "\n",
    "- How to create a classifier for detecting offensive language\n",
    "- How to use words and their part of speech as features\n",
    "- How to evalate the performance of the classifier\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Offenseval data sets\n",
    "\n",
    "The Offenseval codalab websites provides access to the data sets that have been used for the task. We provide the data sets here for this notebook in the folder \"offenseval-datasets\". It is wise to analyse the data sets before starting. We see that the folder contains the following subfolders:\n",
    "\n",
    "- test-A\n",
    "- test-B\n",
    "- test-C\n",
    "- training-v1\n",
    "- trial-data\n",
    "\n",
    "The test folder contain the actual tests used for the shared tasks, corresponding to the three subtasks. The folders contain a readme file that describes the test data in terms of content and format. Read these files to understand what is required. The test data is unlabeled as systems are supposed to generate the labels. Participants had to upload their system output to the codalab platform to get an evaluation. Since we cannot do that anymore, we cannot use the test data.\n",
    "\n",
    "The trial-data were released early on for participants to have an idea about the task before it was released.\n",
    "\n",
    "The training data contain the annotated tweets. The folder contain the following files:\n",
    "\n",
    "- offenseval-annotation.txt: instructions to human annotators how to annotate the tweets\n",
    "- offenseval-training-v1.tsv\n",
    "- readme-trainingset-v1.txt: explaining the content and format of the training data\n",
    "\n",
    "It is wise to "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recipe for building a classifier\n",
    "\n",
    "- Step 1: read the training data to obtain the tweets and their annotations\n",
    "- Step 2: split the data into training data and test data\n",
    "- Step 3: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load data\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def load_data(data_dir, setname):\n",
    "    \n",
    "    \n",
    "    test_path = 'trial-data/offenseval-trial.txt'\n",
    "    train_path = 'training-v1/offenseval-training-v1.tsv'\n",
    "    \n",
    "    \n",
    "    if setname == 'test':\n",
    "        filepath = data_dir+test_path\n",
    "        data = pd.read_csv(filepath, \n",
    "                       delimiter = '\\t', \n",
    "                       header = None,  \n",
    "                       names=[\"tweet\", \"subtask_a\", \"subtask_b\", \"subtask_c\"])\n",
    "    elif setname == 'train':\n",
    "        filepath = data_dir+train_path\n",
    "        data = pd.read_csv(filepath, delimiter=\"\\t\")\n",
    "        \n",
    "    return data\n",
    "\n",
    "\n",
    "def split_train(train_data):\n",
    "    \n",
    "    # split 90%, 10%\n",
    "    \n",
    "    total = len(train_data)\n",
    "    total_90 = round(total * 0.9)\n",
    "    train_data_split = train_data[:total_90]\n",
    "    validation_data = train_data[total_90:]\n",
    "    return train_data_split, validation_data\n",
    "    \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13240\n"
     ]
    }
   ],
   "source": [
    "# your local path to the offenseval data sets\n",
    "data_dir = 'offenseval/datasets/'\n",
    "\n",
    "# we load the training data in a the variable \"train_data\"\n",
    "train_data = load_data(data_dir, 'train')\n",
    "print(\"The size of the training data len(train_data))\n",
    "# we load the test data in a the variable \"test_data\"\n",
    "test_data = load_data(data_dir, 'test')\n",
    "print(len(train_data))\n",
    "# we split the training data again into train and validation data\n",
    "train_data, val_data = split_train(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          id                                              tweet subtask_a  \\\n",
      "0      86426  @USER She should ask a few native Americans wh...       OFF   \n",
      "1      90194  @USER @USER Go home you‚Äôre drunk!!! @USER #MAG...       OFF   \n",
      "2      16820  Amazon is investigating Chinese employees who ...       NOT   \n",
      "3      62688  @USER Someone should'veTaken\" this piece of sh...       OFF   \n",
      "4      43605  @USER @USER Obama wanted liberals &amp; illega...       NOT   \n",
      "5      97670                  @USER Liberals are all Kookoo !!!       OFF   \n",
      "6      77444                   @USER @USER Oh noes! Tough shit.       OFF   \n",
      "7      52415  @USER was literally just talking about this lo...       OFF   \n",
      "8      45157                         @USER Buy more icecream!!!       NOT   \n",
      "9      13384  @USER Canada doesn‚Äôt need another CUCK! We alr...       OFF   \n",
      "10     82776  @USER @USER @USER It‚Äôs not my fault you suppor...       NOT   \n",
      "11     42992  @USER What‚Äôs the difference between #Kavanaugh...       NOT   \n",
      "12     28414  @USER you are a lying corrupt traitor!!! Nobod...       OFF   \n",
      "13     54920  @USER @USER @USER It should scare every Americ...       NOT   \n",
      "14     56392  @USER @USER @USER @USER @USER @USER @USER @USE...       NOT   \n",
      "15     86735               @USER you are also the king of taste       NOT   \n",
      "16     95686  #MAGA @USER  üé∂ Sing like no one is listening  ...       NOT   \n",
      "17     71446  5/5: @USER The time is right for this House to...       NOT   \n",
      "18     23958  @USER Besides Jax‚Äôs mom and maybe Ope he is ha...       NOT   \n",
      "19     28195  @USER @USER @USER gun control! That is all the...       OFF   \n",
      "20     56117  @USER @USER @USER @USER LOL!!!   Throwing the ...       OFF   \n",
      "21     67757                       @USER @USER You are correct.       NOT   \n",
      "22     12681  @USER @USER Kind of like when conservatives wa...       OFF   \n",
      "23     82904  @USER @USER Da fuck is going on people?   Ther...       OFF   \n",
      "24     63236  @USER Been a Willie fan since before most of y...       NOT   \n",
      "25     77665  @USER Tbh these days i just don't like people ...       OFF   \n",
      "26     83484  South Korean Official: ‚ÄúLeaders will discuss s...       NOT   \n",
      "27     74932        @USER @USER You can tell he is a hooper too       NOT   \n",
      "28     91252   @USER I feel like he is better chasing the title       NOT   \n",
      "29     25440  @USER @USER @USER She?  To whom are you referr...       OFF   \n",
      "...      ...                                                ...       ...   \n",
      "11886  19390  @USER üëÄ sitting here thinking he has a killer ...       OFF   \n",
      "11887  74520  @USER @USER It's hilarious that liberals think...       OFF   \n",
      "11888  26800  @USER @USER @USER @USER @USER @USER Never goin...       NOT   \n",
      "11889  16260  @USER @USER Actually what caused these tragedi...       NOT   \n",
      "11890  58852  @USER @USER @USER 1. Depends on what you mean ...       NOT   \n",
      "11891  83945  @USER Here are the People\" who \"Hold you up\" a...       NOT   \n",
      "11892  31387  @USER @USER You are reciting conspiracy theori...       NOT   \n",
      "11893  26156          @USER this photo does you no justice. URL       NOT   \n",
      "11894  32891  @USER @USER @USER @USER @USER @USER @USER @USE...       NOT   \n",
      "11895  19686  @USER Hold the damn vote. Iowa voter chiming I...       NOT   \n",
      "11896  62223  @USER @USER @USER Not just ‚Äúliberals‚Äù there is...       OFF   \n",
      "11897  91059  @USER @USER @USER @USER @USER @USER H1v3 does ...       NOT   \n",
      "11898  57048                                 @USER HE is Satan!       OFF   \n",
      "11899  36705  @USER YOU!!! Need to leave a lot of shit in th...       OFF   \n",
      "11900  49007  . ^___^  ( ‚ñ∞ ‚ñîÁöø‚ñî  ) /   Ooh! you are the ‚ôëCapr...       NOT   \n",
      "11901  92939                  @USER He's as ignorant as it gets       NOT   \n",
      "11902  63764  @USER .... what's so hard about doing that? co...       NOT   \n",
      "11903  78673  @USER @USER @USER @USER @USER @USER @USER @USE...       NOT   \n",
      "11904  63221  Women were treated as 2nd class citizens for t...       NOT   \n",
      "11905  59515  @USER I mean if he is willing to move up for C...       NOT   \n",
      "11906  11777  A 5th columnist always imagines himself as a p...       OFF   \n",
      "11907  53285            @USER Carrey should be shut up for good       OFF   \n",
      "11908  90561  @USER Oh the Liberals will shove race in every...       NOT   \n",
      "11909  62274  @USER @USER @USER @USER @USER @USER @USER @USE...       NOT   \n",
      "11910  47451  @USER @USER @USER But the judges decision was ...       NOT   \n",
      "11911  45588  @USER Because he didn‚Äôt do any think Sorry tha...       OFF   \n",
      "11912  57812  @USER Its a hail mary pass to show her constit...       NOT   \n",
      "11913  18891                  @USER He is leaning the wrong way       NOT   \n",
      "11914  62896  @USER 18 USC sec. 2383 et al. Time to press Fe...       OFF   \n",
      "11915  68177  @USER @USER @USER @USER @USER @USER @USER @USE...       NOT   \n",
      "\n",
      "      subtask_b subtask_c  \n",
      "0           UNT       NaN  \n",
      "1           TIN       IND  \n",
      "2           NaN       NaN  \n",
      "3           UNT       NaN  \n",
      "4           NaN       NaN  \n",
      "5           TIN       OTH  \n",
      "6           UNT       NaN  \n",
      "7           TIN       GRP  \n",
      "8           NaN       NaN  \n",
      "9           TIN       IND  \n",
      "10          NaN       NaN  \n",
      "11          NaN       NaN  \n",
      "12          TIN       IND  \n",
      "13          NaN       NaN  \n",
      "14          NaN       NaN  \n",
      "15          NaN       NaN  \n",
      "16          NaN       NaN  \n",
      "17          NaN       NaN  \n",
      "18          NaN       NaN  \n",
      "19          TIN       OTH  \n",
      "20          TIN       IND  \n",
      "21          NaN       NaN  \n",
      "22          TIN       GRP  \n",
      "23          TIN       GRP  \n",
      "24          NaN       NaN  \n",
      "25          TIN       IND  \n",
      "26          NaN       NaN  \n",
      "27          NaN       NaN  \n",
      "28          NaN       NaN  \n",
      "29          UNT       NaN  \n",
      "...         ...       ...  \n",
      "11886       UNT       NaN  \n",
      "11887       TIN       IND  \n",
      "11888       NaN       NaN  \n",
      "11889       NaN       NaN  \n",
      "11890       NaN       NaN  \n",
      "11891       NaN       NaN  \n",
      "11892       NaN       NaN  \n",
      "11893       NaN       NaN  \n",
      "11894       NaN       NaN  \n",
      "11895       NaN       NaN  \n",
      "11896       TIN       GRP  \n",
      "11897       NaN       NaN  \n",
      "11898       TIN       IND  \n",
      "11899       TIN       IND  \n",
      "11900       NaN       NaN  \n",
      "11901       NaN       NaN  \n",
      "11902       NaN       NaN  \n",
      "11903       NaN       NaN  \n",
      "11904       NaN       NaN  \n",
      "11905       NaN       NaN  \n",
      "11906       TIN       GRP  \n",
      "11907       TIN       IND  \n",
      "11908       NaN       NaN  \n",
      "11909       NaN       NaN  \n",
      "11910       NaN       NaN  \n",
      "11911       TIN       IND  \n",
      "11912       NaN       NaN  \n",
      "11913       NaN       NaN  \n",
      "11914       TIN       IND  \n",
      "11915       NaN       NaN  \n",
      "\n",
      "[11916 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "print(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                 tweet subtask_a subtask_b  \\\n",
      "0    @BreitbartNews OK Shannon, YOU tell the vetera...       NOT       NaN   \n",
      "1    @LeftyGlenn @jaredeker @BookUniverse @hashtagz...       NOT       NaN   \n",
      "2    Hot Mom Sucks Off Step Son In Shower 8 min htt...       OFF       UNT   \n",
      "3    bro these are some cute butt plugs I‚Äôm trying ...       OFF       UNT   \n",
      "4    Arizona Supreme Court strikes down state legis...       NOT       NaN   \n",
      "5    Arguing gun control is wrong of me whoever has...       NOT       NaN   \n",
      "6    Doctors‚Äô interest in medical marijuana far out...       NOT       NaN   \n",
      "7    A must-read and a must-share for all your frie...       NOT       NaN   \n",
      "8    @Jo2timess Now that‚Äôs the dumbest shit I have ...       OFF       UNT   \n",
      "9    Agreed! When all of this drama was unfolding a...       OFF       UNT   \n",
      "10   @NewYorker On the condition of self-reading af...       NOT       NaN   \n",
      "11   Surprise Vote in Congress Protects Medical Mar...       NOT       NaN   \n",
      "12   Nationwide support for gun control falls https...       NOT       NaN   \n",
      "13   @NOA2iCY ooooh i love pineapples. i‚Äôm hoping t...       NOT       NaN   \n",
      "14   Columbia Care expands home delivery service to...       NOT       NaN   \n",
      "15     @BreitbartNews Stunning !!! Obama is everywhere       NOT       NaN   \n",
      "16   When John from the @cNationChannel asked our C...       NOT       NaN   \n",
      "17   it was sexy when this girl told me it was impr...       NOT       NaN   \n",
      "18   @batsai @visiblecare I agree it is very unfort...       NOT       NaN   \n",
      "19   @cattunneycbc @pdmcleod yeah anyone who says t...       OFF       UNT   \n",
      "20   Medical marijuana shops lack votes in Collier;...       NOT       NaN   \n",
      "21   79 percent of people answered this correctly. ...       NOT       NaN   \n",
      "22   She‚Äôs right...he is pretty awesome! @Rockies ....       NOT       NaN   \n",
      "23     @BreitbartNews Guess he can just mute them then       NOT       NaN   \n",
      "24   Support for gun control slips in new poll http...       NOT       NaN   \n",
      "25   Cyrus is a sweet, affectionate boy who loves t...       NOT       NaN   \n",
      "26   @hughhewitt @mishacollins What the hell...? Wh...       OFF       TIN   \n",
      "27   And not give a single fuck. https://t.co/b6vch...       OFF       UNT   \n",
      "28   Guess ima have to beat some lil kids asses tod...       OFF       TTH   \n",
      "29   Prayer: Keep it simple Keep it honest Keep it ...       NOT       NaN   \n",
      "..                                                 ...       ...       ...   \n",
      "290  Don't you just hate when you are out and about...       NOT       NaN   \n",
      "291        üòçüòçüòçüòç he is fine asf https://t.co/HczseFrHQu       OFF       UNT   \n",
      "292  @FoxNews Liberals are losing their minds. They...       NOT       NaN   \n",
      "293                @BreitbartNews What did she resist?       NOT       NaN   \n",
      "294  @Glinner check this cunt out! https://t.co/H03...       OFF       UNT   \n",
      "295  @seanhannity Yeah thanks to your Nobel Emmy aw...       OFF       TIN   \n",
      "296  @LauraLoomer It is amazing how short sighted o...       NOT       NaN   \n",
      "297  @BreitbartNews Can anyone say judicial overrea...       NOT       NaN   \n",
      "298  @BreitbartNews Why the hell does anything need...       NOT       NaN   \n",
      "299  @TravisYeggy @MrGoodMemes @NathanHRubin LOL! I...       NOT       NaN   \n",
      "300  @NewYorker And apparently Congress is willing ...       NOT       NaN   \n",
      "301               she got them ass shots that i like üëÖ       OFF       UNT   \n",
      "302            @thecomeback @JABItalia Fuck @APrecourt       OFF       TIN   \n",
      "303  Hey @LIRR , you are disgusting. https://t.co/K...       OFF       TIN   \n",
      "304                                    @NewYorker Same       NOT       NaN   \n",
      "305  There is no such thing as gun control, there i...       NOT       NaN   \n",
      "306  @NewYorker Here's some positive literature for...       NOT       NaN   \n",
      "307  @NewYorker Just because she'd be the first don...       NOT       NaN   \n",
      "308  DFS Hitman Lineup - DraftKings Only (GS vs. HO...       NOT       NaN   \n",
      "309  If you missed the Dateline episode - Growing P...       NOT       NaN   \n",
      "310  The Santa Fe shooter is not a victim\" he is a ...       NOT       NaN   \n",
      "311  Im really grateful and i really feel special t...       NOT       NaN   \n",
      "312  @jchaltiwanger I guess this did reveal that we...       NOT       NaN   \n",
      "313  This looks like a really weird orgasm.\" https:...       NOT       NaN   \n",
      "314  @MrsMeganTheRed Sometimes my brain hits upon a...       NOT       NaN   \n",
      "315  @Providence1775 @SoCalTheist @TakeThatEpi @Ros...       NOT       NaN   \n",
      "316  Gun control support fades three months after F...       NOT       NaN   \n",
      "317  The hardest day to save is today!\" So if it is...       NOT       NaN   \n",
      "318  Rest well, Christian. The fact that you died i...       NOT       NaN   \n",
      "319  HAHAHA WHAT??? So does that mean the WWE Super...       OFF       UNT   \n",
      "\n",
      "    subtask_c  \n",
      "0         NaN  \n",
      "1         NaN  \n",
      "2         NaN  \n",
      "3         NaN  \n",
      "4         NaN  \n",
      "5         NaN  \n",
      "6         NaN  \n",
      "7         NaN  \n",
      "8         NaN  \n",
      "9         NaN  \n",
      "10        NaN  \n",
      "11        NaN  \n",
      "12        NaN  \n",
      "13        NaN  \n",
      "14        NaN  \n",
      "15        NaN  \n",
      "16        NaN  \n",
      "17        NaN  \n",
      "18        NaN  \n",
      "19        NaN  \n",
      "20        NaN  \n",
      "21        NaN  \n",
      "22        NaN  \n",
      "23        NaN  \n",
      "24        NaN  \n",
      "25        NaN  \n",
      "26        IND  \n",
      "27        NaN  \n",
      "28        IND  \n",
      "29        NaN  \n",
      "..        ...  \n",
      "290       NaN  \n",
      "291       NaN  \n",
      "292       NaN  \n",
      "293       NaN  \n",
      "294       NaN  \n",
      "295       IND  \n",
      "296       NaN  \n",
      "297       NaN  \n",
      "298       NaN  \n",
      "299       NaN  \n",
      "300       NaN  \n",
      "301       NaN  \n",
      "302       IND  \n",
      "303       ORG  \n",
      "304       NaN  \n",
      "305       NaN  \n",
      "306       NaN  \n",
      "307       NaN  \n",
      "308       NaN  \n",
      "309       NaN  \n",
      "310       NaN  \n",
      "311       NaN  \n",
      "312       NaN  \n",
      "313       NaN  \n",
      "314       NaN  \n",
      "315       NaN  \n",
      "316       NaN  \n",
      "317       NaN  \n",
      "318       NaN  \n",
      "319       NaN  \n",
      "\n",
      "[320 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "print(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      id                                              tweet subtask_a  \\\n",
      "0  86426  @USER She should ask a few native Americans wh...       OFF   \n",
      "1  90194  @USER @USER Go home you‚Äôre drunk!!! @USER #MAG...       OFF   \n",
      "2  16820  Amazon is investigating Chinese employees who ...       NOT   \n",
      "3  62688  @USER Someone should'veTaken\" this piece of sh...       OFF   \n",
      "4  43605  @USER @USER Obama wanted liberals &amp; illega...       NOT   \n",
      "\n",
      "  subtask_b subtask_c  \n",
      "0       UNT       NaN  \n",
      "1       TIN       IND  \n",
      "2       NaN       NaN  \n",
      "3       UNT       NaN  \n",
      "4       NaN       NaN  \n"
     ]
    }
   ],
   "source": [
    "print(train_data[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet=train_data[0:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      id                                              tweet subtask_a  \\\n",
      "0  86426  @USER She should ask a few native Americans wh...       OFF   \n",
      "\n",
      "  subtask_b subtask_c  \n",
      "0       UNT       NaN  \n"
     ]
    }
   ],
   "source": [
    "print(tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Preprocess\n",
    "\n",
    "# tokenize, remove stop-words\n",
    "\n",
    "# lemmatize? \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "tweets_to_count_vec() missing 1 required positional argument: 'tweets_test'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-ed2530fe97c2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mtrain_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_X\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtweets_to_count_vec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'tweet'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'tweet'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0mtest_X\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtweets_to_count_vec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'tweet'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: tweets_to_count_vec() missing 1 required positional argument: 'tweets_test'"
     ]
    }
   ],
   "source": [
    "# transform to count vectors\n",
    "\n",
    "# to do:\n",
    "# tokenize and lemmatize, get rid of stop words, punct,  etc\n",
    "# add function for embeddings\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "def tweets_to_count_vec(tweets_train, tweets_test):\n",
    "    \n",
    "    vectorizer = CountVectorizer()\n",
    "    train_X = vectorizer.fit_transform(tweets_train)\n",
    "    test_X = vectorizer.transform(tweets_test)\n",
    "    \n",
    "    \n",
    "    return train_X, test_X\n",
    "\n",
    "train_X, val_X = tweets_to_count_vec(train_data['tweet'], val_data['tweet'])\n",
    " \n",
    "#test_X = tweets_to_count_vec(test_data['tweet'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 891)\t1\n",
      "  (0, 1225)\t1\n",
      "  (0, 6200)\t1\n",
      "  (0, 8545)\t1\n",
      "  (0, 10746)\t1\n",
      "  (0, 11292)\t1\n",
      "  (0, 14301)\t1\n",
      "  (0, 14407)\t1\n",
      "  (0, 15656)\t1\n",
      "  (0, 15927)\t1\n",
      "  (0, 15998)\t1\n",
      "  (0, 16889)\t1\n",
      "  (0, 17444)\t1\n",
      "  (1, 5184)\t1\n",
      "  (1, 6967)\t1\n",
      "  (1, 7739)\t1\n",
      "  (1, 9775)\t1\n",
      "  (1, 13014)\t1\n",
      "  (1, 16416)\t1\n",
      "  (1, 16870)\t1\n",
      "  (1, 16889)\t3\n",
      "  (1, 17866)\t1\n",
      "  (2, 870)\t2\n",
      "  (2, 916)\t1\n",
      "  (2, 1142)\t1\n",
      "  :\t:\n",
      "  (11914, 744)\t1\n",
      "  (11914, 932)\t1\n",
      "  (11914, 2947)\t1\n",
      "  (11914, 3986)\t1\n",
      "  (11914, 5646)\t1\n",
      "  (11914, 5688)\t1\n",
      "  (11914, 6140)\t1\n",
      "  (11914, 7717)\t1\n",
      "  (11914, 11292)\t1\n",
      "  (11914, 11454)\t1\n",
      "  (11914, 12431)\t1\n",
      "  (11914, 14033)\t1\n",
      "  (11914, 14055)\t1\n",
      "  (11914, 15567)\t1\n",
      "  (11914, 15902)\t1\n",
      "  (11914, 16093)\t1\n",
      "  (11914, 16140)\t1\n",
      "  (11914, 16870)\t1\n",
      "  (11914, 16881)\t1\n",
      "  (11914, 16889)\t1\n",
      "  (11915, 6386)\t1\n",
      "  (11915, 11220)\t1\n",
      "  (11915, 12658)\t1\n",
      "  (11915, 16889)\t13\n",
      "  (11915, 17005)\t2\n"
     ]
    }
   ],
   "source": [
    "print(train_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 788)\t1\n",
      "  (0, 932)\t3\n",
      "  (0, 2546)\t1\n",
      "  (0, 2647)\t1\n",
      "  (0, 3857)\t1\n",
      "  (0, 6430)\t1\n",
      "  (0, 6456)\t3\n",
      "  (0, 7564)\t1\n",
      "  (0, 8844)\t1\n",
      "  (0, 9775)\t1\n",
      "  (0, 10538)\t1\n",
      "  (0, 11220)\t1\n",
      "  (0, 11463)\t1\n",
      "  (0, 13788)\t1\n",
      "  (0, 14189)\t1\n",
      "  (0, 15884)\t1\n",
      "  (0, 15891)\t1\n",
      "  (0, 15902)\t1\n",
      "  (0, 16155)\t1\n",
      "  (0, 16889)\t1\n",
      "  (0, 17337)\t1\n",
      "  (0, 17866)\t1\n",
      "  (0, 17880)\t2\n",
      "  (1, 788)\t1\n",
      "  (1, 1808)\t1\n",
      "  :\t:\n",
      "  (1320, 16179)\t1\n",
      "  (1321, 932)\t1\n",
      "  (1321, 3926)\t1\n",
      "  (1321, 5011)\t1\n",
      "  (1321, 6770)\t1\n",
      "  (1321, 6920)\t1\n",
      "  (1321, 13344)\t1\n",
      "  (1321, 15998)\t1\n",
      "  (1321, 16889)\t1\n",
      "  (1321, 17337)\t1\n",
      "  (1321, 17528)\t1\n",
      "  (1322, 12800)\t1\n",
      "  (1322, 16889)\t1\n",
      "  (1323, 932)\t1\n",
      "  (1323, 2826)\t1\n",
      "  (1323, 5991)\t1\n",
      "  (1323, 6581)\t1\n",
      "  (1323, 7889)\t1\n",
      "  (1323, 8545)\t1\n",
      "  (1323, 8817)\t1\n",
      "  (1323, 14266)\t1\n",
      "  (1323, 14893)\t1\n",
      "  (1323, 16870)\t1\n",
      "  (1323, 16889)\t16\n",
      "  (1323, 17177)\t1\n"
     ]
    }
   ],
   "source": [
    "print(val_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "must be real number, not str",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-13af6f4c8bf9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mtrain_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'subtask_a'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_X\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-13af6f4c8bf9>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(train_X, train_y)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msvm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSVC\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgamma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'scale'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    185\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m         \u001b[0mseed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrnd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miinfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'i'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m         \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msolver_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_seed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m         \u001b[0;31m# see comment on the other call to np.iinfo in this file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py\u001b[0m in \u001b[0;36m_sparse_fit\u001b[0;34m(self, X, y, sample_weight, solver_type, kernel, random_seed)\u001b[0m\n\u001b[1;32m    274\u001b[0m                 \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcache_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepsilon\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m                 \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshrinking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprobability\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_iter\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 276\u001b[0;31m                 random_seed)\n\u001b[0m\u001b[1;32m    277\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_warn_from_fit_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32msklearn/svm/libsvm_sparse.pyx\u001b[0m in \u001b[0;36msklearn.svm.libsvm_sparse.libsvm_sparse_train\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: must be real number, not str"
     ]
    }
   ],
   "source": [
    "# classify\n",
    "\n",
    "from sklearn import svm\n",
    "\n",
    "def train(train_X, train_y):\n",
    "    \n",
    "    clf = svm.SVC(gamma='scale')\n",
    "    clf.fit(train_X, train_y)  \n",
    "    return clf\n",
    "\n",
    "def predict(clf, test_X):\n",
    "    \n",
    "    predictions = clf.predict(test_X)\n",
    "    return predictions\n",
    "\n",
    "train_y = train_data['subtask_a']\n",
    "\n",
    "clf = train(train_X, train_y)\n",
    "predictions = predict(clf, val_X)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOT NOT\n",
      "NOT NOT\n",
      "OFF NOT\n",
      "NOT NOT\n",
      "OFF NOT\n",
      "OFF NOT\n",
      "OFF NOT\n",
      "NOT NOT\n",
      "OFF NOT\n",
      "OFF NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "OFF NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "OFF NOT\n",
      "NOT NOT\n",
      "OFF NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "OFF NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "OFF NOT\n",
      "NOT NOT\n",
      "OFF NOT\n",
      "NOT NOT\n",
      "OFF NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "OFF NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "OFF NOT\n",
      "OFF NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "OFF NOT\n",
      "OFF NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "OFF NOT\n",
      "OFF NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "OFF NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "OFF NOT\n",
      "NOT NOT\n",
      "OFF NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "OFF NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "OFF NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "OFF NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "OFF NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "OFF NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "OFF NOT\n",
      "OFF NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "OFF NOT\n",
      "NOT NOT\n",
      "OFF NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "OFF NOT\n",
      "OFF NOT\n",
      "NOT NOT\n",
      "OFF NOT\n",
      "NOT NOT\n",
      "OFF NOT\n",
      "OFF NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "OFF NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "OFF NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "OFF NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "OFF NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "OFF NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "OFF NOT\n",
      "OFF NOT\n",
      "OFF NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "OFF NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "OFF NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "OFF NOT\n",
      "OFF NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "OFF NOT\n",
      "NOT NOT\n",
      "OFF NOT\n",
      "NOT NOT\n",
      "OFF NOT\n",
      "OFF NOT\n",
      "OFF NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "OFF NOT\n",
      "OFF NOT\n",
      "NOT NOT\n",
      "OFF NOT\n",
      "OFF NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "OFF NOT\n",
      "OFF NOT\n",
      "OFF NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "OFF NOT\n",
      "OFF NOT\n",
      "OFF NOT\n",
      "OFF NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "OFF NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "OFF NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "OFF NOT\n",
      "OFF NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "OFF NOT\n",
      "OFF NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "OFF NOT\n",
      "NOT NOT\n",
      "OFF NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "OFF NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "OFF NOT\n",
      "OFF NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "OFF NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "OFF NOT\n",
      "OFF NOT\n",
      "NOT NOT\n",
      "OFF NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "OFF NOT\n",
      "NOT NOT\n",
      "OFF NOT\n",
      "NOT NOT\n",
      "OFF NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "OFF NOT\n",
      "NOT NOT\n",
      "OFF NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "OFF NOT\n",
      "OFF NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "OFF NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "OFF NOT\n",
      "NOT NOT\n",
      "OFF NOT\n",
      "OFF NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "OFF NOT\n",
      "NOT NOT\n",
      "OFF NOT\n",
      "NOT NOT\n",
      "OFF NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "OFF NOT\n",
      "OFF NOT\n",
      "OFF NOT\n",
      "OFF NOT\n",
      "OFF NOT\n",
      "NOT NOT\n",
      "OFF NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "OFF NOT\n",
      "OFF NOT\n",
      "OFF NOT\n",
      "OFF NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "OFF NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "OFF NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "OFF NOT\n",
      "NOT NOT\n",
      "OFF NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "OFF NOT\n",
      "NOT NOT\n",
      "OFF NOT\n",
      "NOT NOT\n",
      "OFF NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "OFF NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "OFF NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "OFF NOT\n",
      "NOT NOT\n",
      "OFF NOT\n",
      "OFF NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "OFF NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "OFF NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "OFF NOT\n",
      "OFF NOT\n",
      "OFF NOT\n",
      "NOT NOT\n",
      "OFF NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "OFF NOT\n",
      "NOT NOT\n",
      "OFF NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "OFF NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "OFF NOT\n",
      "OFF NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "OFF NOT\n",
      "OFF NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "OFF NOT\n",
      "NOT NOT\n",
      "OFF NOT\n",
      "OFF NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "OFF NOT\n",
      "NOT NOT\n",
      "OFF NOT\n",
      "OFF NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "OFF NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "OFF NOT\n",
      "NOT NOT\n",
      "OFF NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "OFF NOT\n",
      "OFF NOT\n",
      "OFF NOT\n",
      "OFF NOT\n",
      "NOT NOT\n",
      "OFF NOT\n",
      "OFF NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "OFF NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "OFF NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "OFF NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "OFF NOT\n",
      "OFF NOT\n",
      "NOT NOT\n",
      "OFF NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "OFF NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "OFF NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "OFF NOT\n",
      "NOT NOT\n",
      "OFF NOT\n",
      "NOT NOT\n",
      "OFF NOT\n",
      "NOT NOT\n",
      "OFF NOT\n",
      "NOT NOT\n",
      "OFF NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "OFF NOT\n",
      "NOT NOT\n",
      "OFF NOT\n",
      "OFF NOT\n",
      "OFF NOT\n",
      "NOT NOT\n",
      "OFF NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "OFF NOT\n",
      "OFF NOT\n",
      "NOT NOT\n",
      "OFF NOT\n",
      "NOT NOT\n",
      "OFF NOT\n",
      "NOT NOT\n",
      "OFF NOT\n",
      "OFF NOT\n",
      "NOT NOT\n",
      "OFF NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "OFF NOT\n",
      "OFF NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "OFF NOT\n",
      "OFF NOT\n",
      "NOT NOT\n",
      "OFF NOT\n",
      "OFF NOT\n",
      "OFF NOT\n",
      "OFF NOT\n",
      "OFF NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "OFF NOT\n",
      "OFF NOT\n",
      "OFF NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "OFF NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "OFF NOT\n",
      "NOT NOT\n",
      "OFF NOT\n",
      "OFF NOT\n",
      "NOT NOT\n",
      "OFF NOT\n",
      "OFF NOT\n",
      "OFF NOT\n",
      "OFF NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "OFF NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "OFF NOT\n",
      "OFF NOT\n",
      "OFF NOT\n",
      "OFF NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "OFF NOT\n",
      "NOT NOT\n",
      "OFF NOT\n",
      "OFF NOT\n",
      "NOT NOT\n",
      "OFF NOT\n",
      "NOT NOT\n",
      "OFF NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "OFF NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "OFF NOT\n",
      "OFF NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "OFF NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "OFF NOT\n",
      "OFF NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "OFF NOT\n",
      "OFF NOT\n",
      "OFF NOT\n",
      "OFF NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "OFF NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "OFF NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "OFF NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "OFF NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "OFF NOT\n",
      "OFF NOT\n",
      "OFF NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "OFF NOT\n",
      "NOT NOT\n",
      "OFF NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "OFF NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "OFF NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "OFF NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "OFF NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "OFF NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "OFF NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "OFF NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "OFF NOT\n",
      "OFF NOT\n",
      "OFF NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "OFF NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "OFF NOT\n",
      "OFF NOT\n",
      "OFF NOT\n",
      "OFF NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "OFF NOT\n",
      "NOT NOT\n",
      "OFF NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "OFF NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "OFF NOT\n",
      "NOT NOT\n",
      "OFF NOT\n",
      "NOT NOT\n",
      "OFF NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "OFF NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "OFF NOT\n",
      "NOT NOT\n",
      "OFF NOT\n",
      "OFF NOT\n",
      "OFF NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "OFF NOT\n",
      "NOT NOT\n",
      "OFF NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "OFF NOT\n",
      "OFF NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "OFF NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "OFF NOT\n",
      "OFF NOT\n",
      "NOT NOT\n",
      "OFF NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "OFF NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "OFF NOT\n",
      "OFF NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "OFF NOT\n",
      "OFF NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "OFF NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "OFF NOT\n",
      "NOT NOT\n",
      "OFF NOT\n",
      "OFF NOT\n",
      "NOT NOT\n",
      "OFF NOT\n",
      "OFF NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "OFF NOT\n",
      "NOT NOT\n",
      "OFF NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "OFF NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "OFF NOT\n",
      "OFF NOT\n",
      "OFF NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "OFF NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "OFF NOT\n",
      "OFF NOT\n",
      "NOT NOT\n",
      "OFF NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "OFF NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "OFF NOT\n",
      "OFF NOT\n",
      "OFF NOT\n",
      "OFF NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "OFF NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "OFF NOT\n",
      "NOT NOT\n",
      "OFF NOT\n",
      "OFF NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "OFF NOT\n",
      "NOT NOT\n",
      "OFF NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "OFF NOT\n",
      "OFF NOT\n",
      "NOT NOT\n",
      "OFF NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "OFF NOT\n",
      "OFF NOT\n",
      "NOT NOT\n",
      "OFF NOT\n",
      "NOT NOT\n",
      "OFF NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "OFF NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "OFF NOT\n",
      "OFF NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "OFF NOT\n",
      "NOT NOT\n",
      "OFF NOT\n",
      "NOT NOT\n",
      "OFF NOT\n",
      "NOT NOT\n",
      "OFF NOT\n",
      "OFF NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "OFF NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "OFF NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "OFF NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "OFF NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "OFF NOT\n",
      "OFF NOT\n",
      "NOT NOT\n",
      "OFF NOT\n",
      "OFF NOT\n",
      "OFF NOT\n",
      "NOT NOT\n",
      "OFF NOT\n",
      "NOT NOT\n",
      "OFF NOT\n",
      "OFF NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "OFF NOT\n",
      "NOT NOT\n",
      "OFF NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "OFF NOT\n",
      "NOT NOT\n",
      "OFF NOT\n",
      "OFF NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "OFF NOT\n",
      "OFF NOT\n",
      "OFF NOT\n",
      "NOT NOT\n",
      "OFF NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "OFF NOT\n",
      "OFF NOT\n",
      "OFF NOT\n",
      "NOT NOT\n",
      "OFF NOT\n",
      "OFF NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "OFF NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "OFF NOT\n",
      "OFF NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "OFF NOT\n",
      "NOT NOT\n",
      "OFF NOT\n",
      "NOT NOT\n",
      "OFF NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "OFF NOT\n",
      "NOT NOT\n",
      "OFF NOT\n",
      "NOT NOT\n",
      "OFF NOT\n",
      "NOT NOT\n",
      "OFF NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "OFF NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "OFF NOT\n",
      "NOT NOT\n",
      "OFF NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "OFF NOT\n",
      "NOT NOT\n",
      "OFF NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "OFF NOT\n",
      "OFF NOT\n",
      "NOT NOT\n",
      "OFF NOT\n",
      "OFF NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "OFF NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "OFF NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "OFF NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "OFF NOT\n",
      "OFF NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "OFF NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "OFF NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "OFF NOT\n",
      "OFF NOT\n",
      "NOT NOT\n",
      "OFF NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "OFF NOT\n",
      "NOT NOT\n",
      "OFF NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "OFF NOT\n",
      "OFF NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "OFF NOT\n",
      "OFF NOT\n",
      "NOT NOT\n",
      "OFF NOT\n",
      "NOT NOT\n",
      "OFF NOT\n",
      "NOT NOT\n",
      "OFF NOT\n",
      "OFF NOT\n",
      "NOT NOT\n",
      "OFF NOT\n",
      "OFF NOT\n",
      "OFF NOT\n",
      "NOT NOT\n",
      "OFF NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "OFF NOT\n",
      "OFF NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "OFF NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "OFF NOT\n",
      "OFF NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "OFF NOT\n",
      "NOT NOT\n",
      "OFF NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "OFF NOT\n",
      "OFF NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "OFF NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "OFF NOT\n",
      "OFF NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "OFF NOT\n",
      "NOT NOT\n",
      "OFF NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "OFF NOT\n",
      "OFF NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "OFF NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "OFF NOT\n",
      "OFF NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "OFF NOT\n",
      "OFF NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "OFF NOT\n",
      "OFF NOT\n",
      "OFF NOT\n",
      "OFF NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "OFF NOT\n",
      "NOT NOT\n",
      "OFF NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "OFF NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "OFF NOT\n",
      "OFF NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "OFF NOT\n",
      "NOT NOT\n",
      "OFF NOT\n",
      "NOT NOT\n",
      "OFF NOT\n",
      "OFF NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "OFF NOT\n",
      "OFF NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "OFF NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "OFF NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "OFF NOT\n",
      "OFF NOT\n",
      "NOT NOT\n",
      "OFF NOT\n",
      "OFF NOT\n",
      "OFF NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "OFF NOT\n",
      "NOT NOT\n",
      "OFF NOT\n",
      "OFF NOT\n",
      "OFF NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "OFF NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "OFF NOT\n",
      "NOT NOT\n",
      "OFF NOT\n",
      "OFF NOT\n",
      "OFF NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "OFF NOT\n",
      "OFF NOT\n",
      "OFF NOT\n",
      "NOT NOT\n",
      "OFF NOT\n",
      "OFF NOT\n",
      "OFF NOT\n",
      "OFF NOT\n",
      "NOT NOT\n",
      "OFF NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "OFF NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "OFF NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "OFF NOT\n",
      "OFF NOT\n",
      "OFF NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "OFF NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "OFF NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "OFF NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "OFF NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "NOT NOT\n",
      "OFF NOT\n",
      "NOT NOT\n",
      "OFF NOT\n",
      "OFF NOT\n",
      "NOT NOT\n"
     ]
    }
   ],
   "source": [
    "# evaluate\n",
    "# to do: calculate f-score (you can simply use the scikit learn implementation)\n",
    "for gold, prediction in zip(val_data['subtask_a'], predictions):\n",
    "    print(gold, p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
