{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab3.3 Training an emotion classifier using embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright: Vrije Universiteit Amsterdam, Faculty of Humanities, CLTL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Table of Contents\n",
    "\n",
    "* [Section 1: Quick introduction to embeddings](#section1)\n",
    "* [Section 2: Loading the emotion data](#section2)\n",
    "* [Section 3: Preparing the training and test data](#section3)\n",
    "* [Section 4: Training and applying the model](#section4)\n",
    "* [Section 5: Generating the test report](#section5)\n",
    "* [Section 6: Applying the classifier to your own text](#section6)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Quick introduction to embeddings  <a class=\"anchor\" id =\"section1\"></a> \n",
    "\n",
    "Extracting features manually can get us a long way. In addition to lemma and part-of-speech, people have used other information: features of the previous words (on the left) or the next words (on the right), whether the current word starts with a capital, whether it is an abbreviation, etc.\n",
    "\n",
    "A recent alternative way to create a 'semantic' representation of a word is by word embeddings: mapping words (or phrases) from the vocabulary to vectors of real numbers. Conceptually it involves a mathematical embedding from a space with many dimensions per word to a continuous vector space with a much lower dimension. For this reason, they are called dense representations.\n",
    "\n",
    "In linguistics, word embeddings were discussed in the research area of distributional semantics. The idea is to quantify and categorize semantic similarities between linguistic items based on their distributional properties in large samples of language data. The underlying notion is that \"a word is characterized by the company it keeps\" (Firth). Embeddings are however the weights in the hidden layer of a neural network that is trained to predict the contexts rather than representing the context in a vector directly.\n",
    "\n",
    "### Reference:\n",
    "\n",
    "For a nice explanation how word embedddings can improve classical bag-of-word approaches, check out this page:\n",
    "\n",
    "https://radimrehurek.com/gensim/auto_examples/tutorials/run_word2vec.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are many sites that provide pretrained word2vec models that can be loaded through the *gensim* package. Check out the original data from Google for a word2vec model with 300 dimensions trained from Wikipedia and news: [Google code archive](https://code.google.com/archive/p/word2vec/). \n",
    "Here is a website with many ready to use models: http://vectors.nlpl.eu/repository/\n",
    "\n",
    "Whatever you choose, make sure you can load the model using the 'gensim' package.\n",
    "\n",
    "In this notebook, we will load pre-trained word embeddings, created by [Glove project](https://nlp.stanford.edu/projects/glove/) from Stanford University on twitter data. We hope that twitter model is more adapted to the spoken utterances from the MELD project than the Google model trained on written news and Wikipedia articles.\n",
    "\n",
    "We will load the model with the Gensim package that we used before. You can download the twitter models to your disk from:\n",
    "\n",
    "http://nlp.stanford.edu/data/glove.twitter.27B.zip\n",
    "\n",
    "You can see that different models are provided with different dimensions:\n",
    "\n",
    "Twitter (2B tweets, 27B tokens, 1.2M vocab, uncased, 25d, 50d, 100d, & 200d vectors, 1.42 GB download): glove.twitter.27B.zip\n",
    "\n",
    "We will use the model with 200 dimensions. If your computer cannot handle it, you can try one of the smaller models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you unpack the zip file, you see that the models are provided as text files. To load the data into *gensim*, we need to carry some specific code given in the next cell. Don't worry too much about this code. Adapt the path to your local copy and run the cell to load it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.test.utils import datapath, get_tmpfile\n",
    "from gensim.models import KeyedVectors\n",
    "from gensim.scripts.glove2word2vec import glove2word2vec\n",
    "\n",
    "glove_file = datapath('/Users/piek/Desktop/ONDERWIJS/data/word-embeddings/classical-models/glove-twitter-models/glove.twitter.27B.200d.txt')\n",
    "tmp_file = get_tmpfile(\"test_word2vec.txt\")\n",
    "\n",
    "_ = glove2word2vec(glove_file, tmp_file)\n",
    "word_embedding_model = KeyedVectors.load_word2vec_format(tmp_file)\n",
    "\n",
    "### this model has 200 dimensions so we set the number of features to 200\n",
    "num_features = 200"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of downloading the models to disk, 'gensim' also provides a downloader API to load the model from the web when needed. In the next cell, we use this API to download a word embeddding model trained on tweets. The following cell use the gensim API. Note that it takes some time to download but it saves some disk space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300\n"
     ]
    }
   ],
   "source": [
    "from gensim.models.word2vec import Word2Vec\n",
    "import gensim.downloader as api\n",
    "\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "import gensim.downloader as api\n",
    "\n",
    "wordembeddings = \"glove-twitter-200\"\n",
    "### this model has 200 dimensions so we set the number of features to 200\n",
    "num_features = 200\n",
    "\n",
    "#wordembeddings = \"glove-twitter-25\"\n",
    "### this model has 25 dimensions so we set the number of features to 25\n",
    "#num_features = 25\n",
    "\n",
    "#wordembeddings = \"glove-twitter-50\"\n",
    "### this model has 50 dimensions so we set the number of features to 50\n",
    "#num_features = 50\n",
    "\n",
    "#wordembeddings = \"glove-twitter-100\"\n",
    "### this model has 100 dimensions so we set the number of features to 100\n",
    "#num_features = 100\n",
    "\n",
    "wordembeddings = \"glove-wiki-gigaword-300\"\n",
    "num_features = 300\n",
    "\n",
    "word_embedding_model = api.load(wordembeddings)\n",
    "print(num_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the word embedding model and training the classifier may take a while. If you laptop cannot handle it, use a smaller word embeddings model with less dimensions. Note that the performance of the classifier may be degraded when fewer dimensions are used. Alternatively, you can reduced the number of training data as we will show below but this will also likely affect the performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Depending on the embedding model you have selected, you need to set the number of features that are used to represent the utterances to the number of dimensions. If the value of num_features is different from the dimensions of the model, you get an error creating the embedding representations for the utterances below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check if the model works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.6816747]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "\n",
    "word1='cat'\n",
    "word2='dog'\n",
    "word1_vector=np.array(word_embedding_model[word1]).reshape(1, -1)\n",
    "word2_vector=np.array(word_embedding_model[word2]).reshape(1, -1)\n",
    "print(cosine_similarity(word1_vector, word2_vector))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Loading the emotion data  <a class=\"anchor\" id =\"section2\"></a> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just as with the previous notebook, we load the training and test data from the MELD data set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "\n",
    "filepath = './data/MELD/train_sent_emo.csv'\n",
    "dftrain = pd.read_csv(filepath)\n",
    "### The data has some problematic strings with encoding problems. The next code removes some of these from the utterances\n",
    "# Try to fix encoding\n",
    "dftrain['Utterance'] = dftrain['Utterance'].str.replace(\"\\x92|\\x97|\\x91|\\x93|\\x94|\\x85\", \"'\")\n",
    "\n",
    "filepath = './data/MELD/test_sent_emo.csv'\n",
    "dftest = pd.read_csv(filepath)\n",
    "dftest['Utterance'] = dftest['Utterance'].str.replace(\"\\x92|\\x97|\\x91|\\x93|\\x94|\\x85\", \"'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "### the first loop gets the utterances\n",
    "training_instances = []\n",
    "for utterance in dftrain['Utterance']:\n",
    "    ### we can limit the data to the first 2000 utterances\n",
    "    ##if index==2000:\n",
    "    ##    break\n",
    "    training_instances.append(nltk.tokenize.word_tokenize(utterance))\n",
    "\n",
    "### We use the same loop for the list of emotion labels that correspond with the vector representations of each utterance\n",
    "training_labels = []\n",
    "for label in dftrain['Emotion']:\n",
    "    ### we can limit the data to the first 2000 utterances\n",
    "    ##if index==2000:\n",
    "    ##    break\n",
    "    training_labels.append(label)\n",
    "    \n",
    "### the first loop gets the utterances\n",
    "test_instances = []\n",
    "for utterance in dftest['Utterance']:\n",
    "    test_instances.append(nltk.tokenize.word_tokenize(utterance))\n",
    "\n",
    "### We use the same loop for the list of emotion labels that correspond with the vector representations of each utterance\n",
    "test_labels = []\n",
    "for label in dftest['Emotion']:\n",
    "    test_labels.append(label)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Preparing the training and test data  <a class=\"anchor\" id =\"section3\"></a> \n",
    "\n",
    "The following import are needed again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the previous notebook, we used CountVectorizer to obtain the full vocabulary of the data set and generate vectors for the one-hot-endcoing of each word. In these vectors, each slot represents a word and a value '1' indicates that the word was present in the utterance and a '0' means absence. This results is large and sparse vector representations for each utterance. We have also seen that we can weight the relevance of a word using the 'TF.IDF' function. This still results in large and sparse vectors but weights are more subtle. The down side is sparseness, lack of generalisation and lack robustness. \n",
    "\n",
    "In the following, we are going to represent the utterances by an embedding representation. In fact, we take the word embedding of each token in the utterance and add these together, after which we take the average. All the embeddings have the same number of dimensions in the same order. So if two tokens have a high weight for one dimension then their co-uccurrence in an utterance will enforce that weight. Note that by adding and taking the average, we normalize for the length of the utterance and the order of the tokens is not relevant.\n",
    "\n",
    "Before we create the embedding representations for the utterances, we are going to filter the words by the NLTK stopword list and their frequency. In the case of CountVectorizer this was done for us. In this case, we need to make our own customized function. The next piece of code shows a loop over all utterances from which we extract a list of all tokens. Next, we count these tokens and extract a list of words that occurs above our threshold, which we should set in the same way as for CountVectorizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "frequency_threshold = 4\n",
    "frequent_keywords = []\n",
    "\n",
    "####  We first will collect all tokens from all the utterances from the training data using the NLTL tokenizer\n",
    "alltokens = []\n",
    "for utterance in dftrain['Utterance']:\n",
    "    tokenlist = nltk.tokenize.word_tokenize(utterance)\n",
    "    for token in tokenlist:\n",
    "        alltokens.append(token)\n",
    "#### The Counter function will create a frequency count of all the items. The result is a dictionary       \n",
    "kw_counter = Counter(alltokens)\n",
    "\n",
    "#### We now loop over the dictionary with counts to get the word and the frequency value\n",
    "for word, count in kw_counter.items():\n",
    "    if count>frequency_threshold:\n",
    "        frequent_keywords.append(word)\n",
    "\n",
    "#print(kw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to define two customized function using 'def' to create an embedding representation for each utterance. \n",
    "These functions are taken from: https://www.kaggle.com/varun08/sentiment-analysis-using-word2vec\n",
    "\n",
    "The first function, called 'featureVecMethod', takes the words of the utterance and the embedding model as parameters. The num_features parameter determines the size of the vector. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "unknown_words =[]\n",
    "known_words = []\n",
    "# Function to average all word vectors in a paragraph\n",
    "def featureVecMethod(words, frequent_keywords, stopwords, model, modelword_index, num_features):\n",
    "    # Pre-initialising empty numpy array for speed\n",
    "    # This create a numpy array with the length of the num_features set to zero values\n",
    "    featureVec = np.zeros(num_features,dtype=\"float32\")\n",
    "    nwords = 0\n",
    "        \n",
    "    for word in  words:\n",
    "        #### we only use words that are frequent and not stopwords\n",
    "        if word in frequent_keywords and not word in stop_words:         \n",
    "            if word in index2word_set:\n",
    "                #featureVec = np.add(featureVec,model[word])\n",
    "                featureVec = np.add(featureVec,model[word]/np.linalg.norm(model[word]))\n",
    "\n",
    "                #we keep track of the words detected, just for analysing the data\n",
    "                known_words.append(word)\n",
    "                nwords = nwords + 1\n",
    "            else:\n",
    "                word = word.lower()\n",
    "                if word in index2word_set:\n",
    "                    #featureVec = np.add(featureVec,model[word])\n",
    "                    featureVec = np.add(featureVec,model[word]/np.linalg.norm(model[word]))\n",
    "                    \n",
    "                    #we keep track of the words detected, just for analysing the data\n",
    "                    known_words.append(word)\n",
    "                    nwords = nwords + 1\n",
    "                else:\n",
    "                    #we keep track of the unknown words to see how well our model fits the data\n",
    "                    unknown_words.append(word)\n",
    "                    \n",
    "    # Dividing the result by number of words in each utterance to get average\n",
    "    featureVec = np.divide(featureVec, nwords)\n",
    "    return featureVec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next function just deals with all the data and creates the list of input vectors. This function calls the previous function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for calculating the average feature vector\n",
    "def getAvgFeatureVecs(texts, keywords, stopwords, model, modelword_index, num_features):\n",
    "    counter = 0\n",
    "    #### we initialise a vector with zeros of the type float32\n",
    "    textFeatureVecs = np.zeros((len(texts),num_features),dtype=\"float32\")\n",
    "    \n",
    "    #### We iterate over all the texts\n",
    "    for text in texts:\n",
    "        # Printing a status message every 1000th text, to see what we are processing\n",
    "        if counter%1000 == 0:\n",
    "            print(\"Review %d of %d\"%(counter,len(texts)))\n",
    "        ### Each text is transformed into a vector representation based on the averaged token embedding using the previous function\n",
    "        ### We add these vectors to the total list\n",
    "        textFeatureVecs[counter] = featureVecMethod(text, keywords, stopwords, model, modelword_index,num_features)\n",
    "        counter = counter+1\n",
    "    return textFeatureVecs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now back to our input data. We iterate over the Pandas frame in the same way as before but now we extract for each utterance the embedding representation, using the above two functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/piek/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:5: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
      "  \"\"\"\n",
      "/Users/piek/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:34: RuntimeWarning: invalid value encountered in true_divide\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review 0 of 9989\n",
      "Review 1000 of 9989\n",
      "Review 2000 of 9989\n",
      "Review 3000 of 9989\n",
      "Review 4000 of 9989\n",
      "Review 5000 of 9989\n",
      "Review 6000 of 9989\n",
      "Review 7000 of 9989\n",
      "Review 8000 of 9989\n",
      "Review 9000 of 9989\n"
     ]
    }
   ],
   "source": [
    "# Calculating average feature vector for training set\n",
    "\n",
    "#Converting Index2Word which is a list to a set for better speed in the execution.\n",
    "#Allows for quicker lookup if the words exist\n",
    "index2word_set = set(word_embedding_model.wv.index2word)\n",
    "# We take the stopwords from NLTK\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "### The full list of utterances is passed to our customized function, with the frequent_keywords list, the stopwords, the embedding model, \n",
    "### the index and the number of features that indicates the dimensions of the model\n",
    "trainDataVecs = getAvgFeatureVecs(training_instances, frequent_keywords, stop_words, word_embedding_model, index2word_set, num_features)\n",
    "\n",
    "#### Due to the averaging, there could be infinitive values or NaN values. The next numpy function turns these value to \"0\" scores\n",
    "trainDataVecs = np.nan_to_num(trainDataVecs) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's inspect our training data a bit more. Depending on the break set for loading the training data, you will have a list of vectors with according length:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9989"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(trainDataVecs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can inspect the first element in the list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector length 300\n",
      "[-2.42284834e-02  2.93585472e-02 -1.98888825e-03 -2.60138828e-02\n",
      "  2.12003011e-04 -1.65226236e-02 -1.70849659e-03  2.49614175e-02\n",
      "  8.99223983e-03 -3.20224464e-01  2.05466580e-02  9.02264100e-03\n",
      "  1.72707322e-03  1.63111109e-02  4.60524857e-02  3.75630483e-02\n",
      " -3.11330091e-02 -3.31713678e-03  3.10880831e-04 -1.91136003e-02\n",
      "  3.76915373e-02  3.55959460e-02  1.80483200e-02  1.18826814e-02\n",
      " -3.34082618e-02 -8.30051303e-03  5.46814129e-03 -1.42572133e-03\n",
      " -2.53683683e-02  2.36102045e-02  2.80681020e-03  7.12274387e-02\n",
      " -2.33282633e-02  6.64981361e-03 -1.54919937e-01  2.01730337e-02\n",
      "  5.75820496e-03 -3.80901154e-03 -8.61165114e-03 -7.86029082e-03\n",
      " -1.62166171e-02 -6.09386247e-03 -1.48823317e-02  5.30707687e-02\n",
      " -1.69919785e-02  2.79374905e-02  4.06390727e-02  3.65676470e-02\n",
      " -1.76445320e-02  9.20884591e-03  6.82919938e-03 -1.11794956e-02\n",
      "  3.85308862e-02  8.87811556e-03 -9.13435686e-03  2.98784617e-02\n",
      " -4.92461119e-03  5.87546527e-02  2.46372167e-02 -6.12752233e-03\n",
      "  3.25111933e-02  3.26362364e-02  4.06603627e-02 -8.51673260e-03\n",
      " -1.10627720e-02 -3.60075161e-02 -2.18531117e-02  7.93558266e-03\n",
      " -5.59030753e-03 -2.60053389e-03  1.78855192e-02 -5.08424686e-03\n",
      "  1.42474780e-02  2.37216502e-02 -1.74253378e-02 -9.28773824e-03\n",
      "  2.04488114e-02  1.82262864e-02 -3.14640664e-02  1.15227455e-03\n",
      " -1.52380709e-02  1.84903760e-02  4.46239039e-02 -1.30625907e-02\n",
      "  3.57689187e-02  2.19514035e-02 -2.79688612e-02  1.45243760e-02\n",
      " -1.32924579e-02  1.74055696e-02 -3.62356715e-02  2.20162123e-02\n",
      " -3.67927067e-02 -3.35827991e-02  2.41660811e-02  1.79711811e-03\n",
      " -6.06481545e-02  1.65318437e-02  1.11926440e-02 -7.10369498e-02\n",
      " -2.09544552e-03 -1.72811095e-04 -1.54828662e-02 -1.37920566e-02\n",
      "  2.60969773e-02  4.59353905e-03  1.88779067e-02  4.96163517e-02\n",
      " -3.52315828e-02  3.26411612e-02 -6.09252835e-03 -3.98876891e-02\n",
      " -1.61318574e-03 -3.06217186e-02  2.55097803e-02  2.67714765e-02\n",
      " -2.36015534e-03 -1.23469606e-02  1.89594843e-03 -9.50506236e-03\n",
      " -2.15378925e-02 -1.76935643e-02  1.53254773e-02 -1.56406276e-02\n",
      "  1.03336880e-02 -2.63029411e-02 -5.84263541e-03  2.32863463e-02\n",
      "  2.37730294e-02  1.28143411e-02  2.28296667e-02  2.98894718e-02\n",
      "  2.75339484e-02  4.22968157e-03  4.02447768e-03  1.50510240e-02\n",
      "  2.19006017e-02 -1.20580550e-02  2.19100807e-02  4.32002433e-02\n",
      "  2.99414201e-03  1.45024443e-02  2.78787352e-02  1.35071939e-02\n",
      " -5.99344932e-02  1.79328106e-03  3.77792232e-02 -1.44882053e-02\n",
      " -4.58786003e-02  9.48191155e-05  3.10461316e-02 -4.71324194e-03\n",
      "  3.01580299e-02 -1.61217339e-02  3.49228531e-02  1.03502953e-02\n",
      "  9.76563431e-03  1.24009815e-03  1.07104061e-02 -1.97790507e-02\n",
      "  2.12283917e-02 -4.22441959e-02  4.26647672e-03 -1.15863122e-02\n",
      "  1.21229119e-03  1.56082641e-02 -2.49285735e-02  4.44177389e-02\n",
      "  4.05276893e-03  6.14324734e-02  2.50344649e-02  1.55026950e-02\n",
      " -1.07325807e-01  5.24210744e-03  7.98104331e-03 -3.51190823e-03\n",
      "  9.38870106e-03  6.45072572e-03 -8.28369055e-03  6.89015314e-02\n",
      "  1.87096726e-02  4.31422852e-02  1.80238262e-02 -5.46854734e-03\n",
      " -1.50518864e-02 -2.24902481e-02 -3.16068567e-02  5.69031574e-03\n",
      " -2.21884437e-02  3.94111909e-02 -2.68809684e-02  3.21401060e-02\n",
      " -7.24564772e-03 -1.46580795e-02 -9.25980695e-03 -8.88650119e-03\n",
      "  1.35889882e-03 -2.00782865e-02 -1.89979933e-02 -1.86016597e-02\n",
      "  1.83753297e-01 -2.06593424e-02  1.11999037e-02 -1.53437480e-02\n",
      "  1.44035257e-02  1.36955222e-02 -3.30562182e-02  1.27269896e-02\n",
      " -1.99955748e-03 -1.18567226e-02 -1.43855177e-02 -7.08375964e-03\n",
      "  3.16120610e-02 -1.98417157e-02  2.08980106e-02  1.29076345e-02\n",
      " -2.32191989e-03  2.99286507e-02  1.04229338e-02  3.71662900e-03\n",
      " -8.17978568e-03  7.00578280e-03 -2.43008118e-02  2.64100805e-02\n",
      "  1.92835648e-02  1.90099142e-02  8.83649848e-03 -2.03411398e-03\n",
      " -2.05168296e-02  4.55298275e-03 -1.17283417e-02 -8.98069888e-03\n",
      "  1.07997777e-02 -1.92988254e-02  4.82201297e-03  9.29151662e-03\n",
      "  1.78738721e-02  2.09593773e-02  1.98721350e-03  3.61321829e-02\n",
      "  5.00379689e-03 -9.21686366e-03  6.02495000e-02 -1.16648022e-02\n",
      " -8.16991776e-02  8.12514103e-04  1.54810613e-02 -2.28511672e-02\n",
      "  1.21644773e-02  2.34802323e-03  1.72081906e-02  3.99289653e-03\n",
      " -9.94106755e-03  4.62058280e-03  6.86042011e-02 -1.76206767e-03\n",
      " -1.39438296e-02 -5.02201356e-03  3.63075919e-02 -2.22596042e-02\n",
      " -1.85759813e-02 -3.03943269e-02  9.55757871e-03  3.01194086e-04\n",
      " -1.28531065e-02 -9.08407755e-03  1.67797040e-02 -7.12079182e-03\n",
      "  1.45734735e-02  5.25719672e-02 -5.78255206e-03 -1.72998905e-02\n",
      "  2.01447587e-02  2.58870833e-02  2.23116167e-02  7.78804440e-03\n",
      " -3.32911164e-01 -2.15734486e-02  5.99172935e-02  1.10671641e-02\n",
      " -3.40979695e-02 -3.97261092e-03 -8.71073361e-03 -2.61937641e-02\n",
      " -1.15757165e-02  3.35679464e-02 -1.18931355e-02  1.72826014e-02\n",
      " -7.40912929e-03 -3.67112434e-03  8.61450750e-03 -1.58812273e-02\n",
      " -2.72342414e-02  4.34888247e-03  3.17650959e-02  1.88674666e-02\n",
      "  2.39326851e-03 -5.83510548e-02 -2.59423479e-02  2.38211453e-02]\n"
     ]
    }
   ],
   "source": [
    "print('Vector length', len(trainDataVecs[0]))\n",
    "print (trainDataVecs[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is simply a list with digits, each representing the averaged weight of the tokens or words that made up the utterance. We can checks the length, which should be '300', '100', '50' or '25', etc. depending on the number of dimensions of the word2vec model that you used.\n",
    "\n",
    "There are two major differences with the bag-of-tokens that we used in the previous notebook:\n",
    "\n",
    "1. the vectors are short\n",
    "2. there are no zero's \n",
    "\n",
    "Instead of *large sparse* vectors, we now have *short dense* vectors representing each utterance. Whereas in the previous representation, each slot in the vector corresponds with a token, now each slot is a weight from the hidden layer to learn to predict others words in the context."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is true for each utterance, each having a unique set of values for the same hidden layer weights. These weights now represent the meaning of the utterance for a machine, which can use a similarity function such as cosine similairty to measure the degree of equivalence across these representations. When we inspects any other utterance, we see it is represented in a simlar way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300\n",
      "[-3.34656052e-02 -1.54432449e-02  1.91893093e-02 -5.23057058e-02\n",
      "  1.76805276e-02  4.07470670e-03 -1.71777830e-02  5.14362641e-02\n",
      "  3.88247184e-02 -3.75979602e-01  7.19848052e-02 -1.79710761e-02\n",
      " -3.62468660e-02  6.15833774e-02 -1.57246254e-02  1.22439843e-02\n",
      " -5.39080687e-02  6.31871168e-03  1.29400091e-02 -1.66408233e-02\n",
      " -3.34875961e-03  6.07072338e-02  5.52398674e-02  2.99382154e-02\n",
      " -5.12655266e-02 -2.50904020e-02  4.18722862e-03 -4.78261448e-02\n",
      " -2.41893567e-02  1.42338928e-02 -2.30888464e-02  6.95327073e-02\n",
      " -5.94733842e-02  1.46406349e-02 -2.34109908e-01  5.14502414e-02\n",
      " -3.86457029e-03  4.01513055e-02 -3.06833498e-02 -5.70127089e-03\n",
      "  4.84503731e-02 -4.19773385e-02 -1.20958053e-02  6.38127234e-03\n",
      " -5.32918237e-03  7.74203241e-03  7.32207969e-02  7.64759630e-02\n",
      "  1.09588206e-02  2.62346324e-02  3.51432664e-03 -3.24195810e-02\n",
      "  1.77698527e-02 -3.65351513e-02 -4.13852260e-02  5.94245419e-02\n",
      " -1.62900276e-02  4.39020880e-02  4.44586240e-02 -1.69757474e-02\n",
      "  5.59020117e-02 -1.80822276e-02  4.63844910e-02 -1.36643033e-02\n",
      " -2.47280207e-02 -8.33517164e-02  6.30344301e-02 -1.60654224e-02\n",
      "  3.16026434e-02 -2.03039739e-02 -1.20603340e-02 -2.46040840e-02\n",
      " -1.75073780e-02  3.92858014e-02 -3.48853283e-02 -3.39874662e-02\n",
      "  1.29136620e-02  3.46296430e-02 -2.45933980e-02 -1.38619300e-02\n",
      " -1.17991259e-02 -1.98294036e-03  7.66836032e-02  1.95441451e-02\n",
      "  1.98471304e-02  2.03061979e-02 -1.50986509e-02  1.87661592e-02\n",
      " -1.40619669e-02 -1.05060833e-02 -3.29948738e-02  4.78660986e-02\n",
      " -5.44046387e-02 -5.25566228e-02  4.62443614e-03  7.78502505e-03\n",
      " -3.69493775e-02 -1.29686669e-02 -1.09454617e-02 -1.40023138e-02\n",
      "  1.32189300e-02 -5.83578423e-02 -2.82165757e-03 -2.06560586e-02\n",
      " -5.74951991e-03  1.35989930e-03  1.03036342e-02  4.97972481e-02\n",
      " -5.90033159e-02 -2.04830896e-02 -2.60994695e-02 -6.07328527e-02\n",
      " -8.02989490e-03 -5.49239889e-02  4.86901067e-02  5.37533080e-03\n",
      " -1.47928800e-02 -2.71998309e-02  1.29726855e-02 -1.54473530e-02\n",
      " -2.88085286e-02 -1.92634612e-02  3.97452638e-02  1.08150719e-02\n",
      " -6.13954384e-03  3.71555937e-03  4.54886332e-02  5.71073070e-02\n",
      " -6.78901654e-03  1.88784953e-02  2.28484608e-02  1.65325105e-02\n",
      "  3.90540846e-02 -7.30768684e-03 -2.18582321e-02 -2.49276049e-02\n",
      "  1.99727267e-02 -3.21994871e-02  3.10685076e-02  4.21223417e-02\n",
      " -2.56940015e-02  4.27828692e-02  2.21596509e-02 -2.28887275e-02\n",
      " -6.48309961e-02 -1.15911914e-02  6.82699075e-03 -2.75323689e-02\n",
      " -6.39676675e-02 -8.91452096e-03 -4.31032255e-02 -4.09104563e-02\n",
      "  1.04853716e-02 -8.51919781e-03  5.15018813e-02 -8.54054838e-03\n",
      "  7.33897556e-03 -1.57296490e-02  4.12505195e-02 -2.32232418e-02\n",
      "  2.16520894e-02 -5.64191267e-02  4.10548318e-03 -1.90256275e-02\n",
      "  3.17849219e-04  1.75821595e-02 -2.91992836e-02 -1.58265326e-02\n",
      "  2.38868780e-02  5.37172556e-02  4.36669402e-02  1.74019746e-02\n",
      " -1.44041881e-01  3.67103741e-02  9.39452741e-03  9.31239128e-03\n",
      "  9.23312269e-03 -2.19858401e-02 -8.22878070e-03  4.08285446e-02\n",
      "  1.42065436e-02  4.25446406e-03  4.31227572e-02 -1.58403702e-02\n",
      "  2.56940182e-02 -3.59438434e-02 -1.53689925e-02 -5.05260983e-03\n",
      " -3.82572003e-02  3.76808234e-02 -2.16745976e-02  5.01961112e-02\n",
      "  3.31552178e-02 -2.88178232e-02 -3.02392188e-02 -3.28308791e-02\n",
      " -8.53555650e-03 -5.40715382e-02  2.17837878e-02 -5.37512377e-02\n",
      "  2.18021423e-01 -1.06799202e-02  1.05513511e-02 -1.06461328e-02\n",
      "  2.02821232e-02  2.17560418e-02 -5.69756934e-03  3.35864583e-03\n",
      " -1.32611440e-02 -5.71617000e-02 -2.18051616e-02 -6.74393121e-03\n",
      "  1.99387912e-02 -4.07125950e-02  3.88792120e-02 -3.21905990e-03\n",
      "  6.63180044e-03  4.73343907e-03  2.74447678e-03 -3.91236767e-02\n",
      "  4.45523858e-02  8.03006231e-04 -4.80078980e-02  2.28105374e-02\n",
      " -2.85983477e-02  2.13133320e-02  2.23120842e-02 -1.20404158e-02\n",
      "  1.98597498e-02  1.02805728e-02 -1.18446359e-02 -2.15431005e-02\n",
      "  5.26111722e-02 -6.75341338e-02 -7.91632570e-03  2.74641663e-02\n",
      " -1.04448351e-03  1.18655933e-03 -3.03398184e-02  6.12131171e-02\n",
      "  1.15623865e-02  4.39246930e-02  5.25226779e-02  2.94205397e-02\n",
      " -1.07763506e-01 -9.31533054e-03 -9.37081315e-03  4.16388828e-03\n",
      " -3.30609526e-03  8.78068246e-03  6.09427989e-02 -5.93211465e-02\n",
      " -4.24879044e-02  6.46432582e-03  7.99960196e-02  5.95730245e-02\n",
      "  1.22070601e-02 -4.85307463e-02  1.88531671e-02  6.81409612e-03\n",
      " -1.98545419e-02 -3.37607265e-02  1.45254638e-02  2.40463521e-02\n",
      " -1.31009817e-02  2.02662889e-02 -1.25837233e-02 -4.90610711e-02\n",
      "  1.52739529e-02  2.97105070e-02 -2.35094111e-02 -4.43831459e-02\n",
      " -2.52744975e-03 -3.09138885e-03  2.43134219e-02  4.14848104e-02\n",
      " -3.48021716e-01  5.45454863e-03  6.78617209e-02 -2.36884784e-03\n",
      " -4.10072580e-02  1.93960331e-02  8.47061910e-03  1.69796776e-02\n",
      "  8.06880556e-03  4.49545905e-02 -1.13867614e-02  1.82031654e-02\n",
      "  9.12454724e-03 -3.09623871e-02 -1.51328910e-02 -7.63877388e-03\n",
      " -4.37233336e-02  1.90869290e-02  2.66898088e-02  9.13608912e-03\n",
      " -3.19753215e-02 -5.89830279e-02 -2.69877771e-03  4.36156429e-02]\n"
     ]
    }
   ],
   "source": [
    "print(len(trainDataVecs[1000]))\n",
    "print(trainDataVecs[1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the vectors are compatible, we can compare them in the same way as we did before for the word2vec embeddings of *cat* and *dog*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.8440603]]\n"
     ]
    }
   ],
   "source": [
    "word1_vector=np.array(trainDataVecs[0]).reshape(1, -1)\n",
    "word2_vector=np.array(trainDataVecs[1000]).reshape(1, -1)\n",
    "print(cosine_similarity(word1_vector, word2_vector))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For training, we use the same labels as before:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neutral neutral\n"
     ]
    }
   ],
   "source": [
    "print(training_labels[0], training_labels[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So now we have a numeric representation of each text, based on the embeddings of the words. We feed this to a classifier in the same way as we did in the previous notebooks with the Countvectorizer output.\n",
    "\n",
    "Before we can train the classifier, we stil need to convert the labels to numeric values as we did before."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we do that, it may be good to check which words are not in the embedding model and therefore do not contribute to the representation of the utterance. In the above function, we kept track of the unknown words. Now we can inspect this list. We use the *Counter* function to get a frequency count of these words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data vocabulary statistics:\n",
      "Frequency threshold 4\n",
      "Proportion of unknown tokens 0.009936389232350618\n",
      "Number of unknown words 25\n",
      "Number of unknown word tokens: 667\n",
      "Unknown words counts\n",
      "Counter({\"y'know\": 322, 'pheebs': 79, '..': 42, 'and-and': 26, 'you-you': 20, 'no-no-no': 18, \"i'm-i\": 18, 'i-i-i': 18, 'hey-hey': 14, 'that-that': 12, 'we-we': 10, 'oh-oh': 10, 'what-what': 9, 'no-no-no-no': 8, 'yeah-yeah': 7, \"'kay\": 6, \"it's-it\": 6, 'buffay': 6, 'oh-ho': 6, 'i-i-i-i': 5, 'ok.': 5, \"that's-that\": 5, 'um-hmm': 5, 'the-the': 5, 'heldi': 5})\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "print('Training data vocabulary statistics:')\n",
    "print('Frequency threshold', frequency_threshold)\n",
    "unknown_words_count = Counter(unknown_words)\n",
    "print('Proportion of unknown tokens', len(unknown_words)/(len(unknown_words)+len(known_words)))\n",
    "print('Number of unknown words',len(unknown_words_count))\n",
    "print('Number of unknown word tokens:', len(unknown_words))\n",
    "print('Unknown words counts')\n",
    "print(unknown_words_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also kept track of the *known* words, so lets check these as well:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of known words 1113\n",
      "Number of known words tokens: 66460\n"
     ]
    }
   ],
   "source": [
    "known_words_count = Counter(known_words)\n",
    "print('Number of known words',len(known_words_count))\n",
    "print('Number of known words tokens:', len(known_words))\n",
    "#print(known_words_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we represent the test data with the same methods to make them compatible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review 0 of 2610\n",
      "Review 1000 of 2610\n",
      "Review 2000 of 2610\n",
      "Test data vocabulary statistics:\n",
      "Frequency threshold 4\n",
      "Proportion of unknown tokens 0.009801611611139908\n",
      "Number of unknown words 25\n",
      "Number of unknown word tokens: 832\n",
      "Unknown words counts\n",
      "Counter({\"y'know\": 433, 'pheebs': 88, '..': 50, 'and-and': 28, 'i-i-i': 27, 'you-you': 26, 'no-no-no': 21, \"i'm-i\": 20, 'hey-hey': 16, 'we-we': 12, 'that-that': 12, 'what-what': 11, 'oh-oh': 10, 'no-no-no-no': 9, \"'kay\": 8, 'buffay': 8, 'yeah-yeah': 7, 'oh-ho': 7, 'the-the': 7, 'ok.': 6, \"it's-it\": 6, 'i-i-i-i': 5, \"that's-that\": 5, 'um-hmm': 5, 'heldi': 5})\n",
      "Number of known words 1113\n",
      "Number of known words tokens: 84052\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/piek/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:34: RuntimeWarning: invalid value encountered in true_divide\n"
     ]
    }
   ],
   "source": [
    "testDataVecs = getAvgFeatureVecs(test_instances, frequent_keywords, stop_words, word_embedding_model, index2word_set, num_features)\n",
    "\n",
    "#### Due to the averaging, there could be infinitive values or NaN values. The next numpy function turns these value to \"0\" scores\n",
    "testDataVecs = np.nan_to_num(testDataVecs) \n",
    "\n",
    "print('Test data vocabulary statistics:')\n",
    "print('Frequency threshold', frequency_threshold)\n",
    "\n",
    "\n",
    "unknown_words_count = Counter(unknown_words)\n",
    "print('Proportion of unknown tokens', len(unknown_words)/(len(unknown_words)+len(known_words)))\n",
    "print('Number of unknown words',len(unknown_words_count))\n",
    "print('Number of unknown word tokens:', len(unknown_words))\n",
    "print('Unknown words counts')\n",
    "print(unknown_words_count)\n",
    "\n",
    "known_words_count = Counter(known_words)\n",
    "print('Number of known words',len(known_words_count))\n",
    "print('Number of known words tokens:', len(known_words))\n",
    "#print(known_words_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just as in the previous notebook, we need to turn the labels into numerical values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['anger', 'disgust', 'fear', 'joy', 'neutral', 'sadness', 'surprise']\n",
      "Train labels [4, 4, 4, 4, 6, 4, 4, 4, 4, 4, 2, 4, 6, 4, 6, 5, 6, 2, 4, 4]\n",
      "Test labels [6, 0, 4, 4, 3, 3, 3, 3, 3, 3, 3, 4, 4, 5, 6, 0, 0, 0, 3, 3]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "# first we instantiate a label encode\n",
    "le = preprocessing.LabelEncoder()\n",
    "# we fee this encoder with the complete list of labels from our data\n",
    "le.fit(training_labels+test_labels)\n",
    "print(list(le.classes_))\n",
    "training_classes = le.transform(training_labels)\n",
    "print('Train labels', list(training_classes[0:20]))\n",
    "\n",
    "test_classes = le.transform(test_labels)\n",
    "print('Test labels', list(test_classes[0:20]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next steps are the same as for the previous notebook, except that we pass the embedding representations of the training data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Training and applying the model  <a class=\"anchor\" id =\"section4\"></a> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
       "          intercept_scaling=1, loss='squared_hinge', max_iter=2000,\n",
       "          multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "          verbose=0)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "# We choose a Linear model\n",
    "svm_linear_clf = svm.LinearSVC(max_iter=2000)\n",
    "### we train the classifier through the *fit* function and by passing the training vectors and the training labels as paramters:\n",
    "svm_linear_clf.fit(trainDataVecs, training_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting the Test set results, find macro recall\n",
    "y_pred_svm_linear = svm_linear_clf.predict(testDataVecs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Generating the test report  <a class=\"anchor\" id =\"section5\"></a> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['anger' 'disgust' 'fear' 'joy' 'neutral' 'sadness' 'surprise']\n",
      "Embeddings SVM LINEAR ----------------------------------------------------------------\n",
      "Word embedding model used glove-wiki-gigaword-300\n",
      "Word frequency threshold 4\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0  0.4761905 0.1159420 0.1864802       345\n",
      "           1  0.0000000 0.0000000 0.0000000        68\n",
      "           2  0.0000000 0.0000000 0.0000000        50\n",
      "           3  0.4582210 0.4228856 0.4398448       402\n",
      "           4  0.6007194 0.9307325 0.7301686      1256\n",
      "           5  0.5882353 0.0480769 0.0888889       208\n",
      "           6  0.5654450 0.3843416 0.4576271       281\n",
      "\n",
      "    accuracy                      0.5735632      2610\n",
      "   macro avg  0.3841159 0.2717112 0.2718585      2610\n",
      "weighted avg  0.5303591 0.5735632 0.5001254      2610\n",
      "\n",
      "Confusion matrix\n",
      "[[  40    0    0   81  197    2   25]\n",
      " [   3    0    0    9   53    0    3]\n",
      " [   2    0    0   10   35    1    2]\n",
      " [   7    0    0  170  210    0   15]\n",
      " [   8    0    1   41 1169    3   34]\n",
      " [  12    0    0   14  168   10    4]\n",
      " [  12    0    0   46  114    1  108]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/piek/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "#### this report gives the results for the LINEAR classifier\n",
    "report = classification_report(test_classes,y_pred_svm_linear,digits = 7)\n",
    "print(le.classes_)\n",
    "print('Embeddings SVM LINEAR ----------------------------------------------------------------')\n",
    "print('Word embedding model used', wordembeddings)\n",
    "print('Word frequency threshold', frequency_threshold)\n",
    "print(report)\n",
    "print('Confusion matrix')\n",
    "print(sklearn.metrics.confusion_matrix(test_classes,y_pred_svm_linear))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember the results from the notebook where we trained a NaiveBayes and SVM classifiers with one-hot-encodings of the words? Take some time to compare the results and think about the differences."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Applying the model to new data  <a class=\"anchor\" id =\"section6\"></a> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We would like to apply the embedding based model to our own data but this works a bit different as we cannot simply use the 'transform' function to represent the utterances using the one-hot vector representation of the training vocabulary.\n",
    "\n",
    "What we need to do is to create an embedding representation using the same function we used above and assume that our classifier finds sufficient similarity in the embeddings of our data with the correct training data.\n",
    "\n",
    "We use the same set of utterances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# some utterances\n",
    "some_chat = ['That is sweet of you', \n",
    "               'You are so funny', \n",
    "               'Are you a man or a woman?', \n",
    "               'Chatbots make me sad and feel lonely.', \n",
    "               'Your are stupid and boring.', \n",
    "               'Two thumbs up', \n",
    "               'I fell asleep halfway through this conversation', \n",
    "               'Wow, I am really amazed.', \n",
    "               'You are amazing.']\n",
    "\n",
    "\n",
    "len(some_chat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we define the list of labels that go with our chat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "some_chat_emotions = ['joy', 'joy', 'neutral', 'sadness', 'anger', 'joy', 'anger', 'surprise', 'joy']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We  use the LabelEncoder *le* to convert this list into a numpy array with digits:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels ['anger' 'disgust' 'fear' 'joy' 'neutral' 'sadness' 'surprise']\n",
      "[3 3 4 5 0 3 0 6 3]\n"
     ]
    }
   ],
   "source": [
    "print('labels',le.classes_)\n",
    "some_chat_labels = le.transform(some_chat_emotions)\n",
    "print(some_chat_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review 0 of 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/piek/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:34: RuntimeWarning: invalid value encountered in true_divide\n"
     ]
    }
   ],
   "source": [
    "some_chat_tokens = []\n",
    "for utterance in some_chat:\n",
    "    some_chat_tokens.append(nltk.tokenize.word_tokenize(utterance))\n",
    "\n",
    "some_chat_embedding_vectors = getAvgFeatureVecs(some_chat_tokens, frequent_keywords,stop_words, word_embedding_model, index2word_set, num_features)\n",
    "#### Due to the averaging, there could be infinitive values or NaN values. The next numpy function turns these value to \"0\" scores\n",
    "some_chat_embedding_vectors = np.nan_to_num(some_chat_embedding_vectors)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "System predictions [3 3 6 5 0 4 4 6 3]\n",
      "Gold labels [3 3 4 5 0 3 0 6 3]\n",
      "That is sweet of you => joy\n",
      "You are so funny => joy\n",
      "Are you a man or a woman? => surprise\n",
      "Chatbots make me sad and feel lonely. => sadness\n",
      "Your are stupid and boring. => anger\n",
      "Two thumbs up => neutral\n",
      "I fell asleep halfway through this conversation => neutral\n",
      "Wow, I am really amazed. => surprise\n",
      "You are amazing. => joy\n"
     ]
    }
   ],
   "source": [
    "# have classifier make a prediction\n",
    "\n",
    "some_chat_pred = svm_linear_clf.predict(some_chat_embedding_vectors)\n",
    "print('System predictions', some_chat_pred)\n",
    "print('Gold labels', some_chat_labels)\n",
    "for review, predicted_label in zip(some_chat, some_chat_pred):\n",
    "    \n",
    "    print('%s => %s' % (review, \n",
    "                        le.classes_[predicted_label]))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['anger' 'disgust' 'fear' 'joy' 'neutral' 'sadness' 'surprise']\n",
      "Embedding SVM LINEAR ON EXTERNAL DATA -----------------------------\n",
      "Word embedding model used glove-wiki-gigaword-300\n",
      "Word frequency threshold 4\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0  1.0000000 0.5000000 0.6666667         2\n",
      "           3  1.0000000 0.7500000 0.8571429         4\n",
      "           4  0.0000000 0.0000000 0.0000000         1\n",
      "           5  1.0000000 1.0000000 1.0000000         1\n",
      "           6  0.5000000 1.0000000 0.6666667         1\n",
      "\n",
      "    accuracy                      0.6666667         9\n",
      "   macro avg  0.7000000 0.6500000 0.6380952         9\n",
      "weighted avg  0.8333333 0.6666667 0.7142857         9\n",
      "\n"
     ]
    }
   ],
   "source": [
    "report = classification_report(some_chat_labels,some_chat_pred,digits = 7)\n",
    "print(le.classes_)\n",
    "print('Embedding SVM LINEAR ON EXTERNAL DATA -----------------------------')\n",
    "print('Word embedding model used', wordembeddings)\n",
    "print('Word frequency threshold', frequency_threshold)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Saving the classifier to disk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just as with the previous notebook, you can save the emotion classification model to disk and load the model some other time. Note that you need to load the same word2vec model as well to represent any text input with vector representations that are compatible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# save the classifier to disk\n",
    "filename_classifier = './models/svm_linear_clf_embeddings.sav'\n",
    "pickle.dump(svm_nonlinear_clf, open(filename_classifier, 'wb'))\n",
    " \n",
    "# some time later...\n",
    " \n",
    "# load the classifier and the vectorizer from disk\n",
    "loaded_classifier = pickle.load(open(filename_classifier, 'rb'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End of this notebook"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
