{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab1-Assignment\n",
    "\n",
    "This notebook describes the assignment for Lab 1. \n",
    "\n",
    "**Points**: each exercise is prefixed with the number of points you can obtain for the exercise.\n",
    "\n",
    "We assume you have worked through the following notebooks:\n",
    "* **Lab1.1-introduction**\n",
    "* **Lab1.2-introduction-to-NLTK**\n",
    "* **Lab1.3-introduction-to-spaCy** \n",
    "\n",
    "In this assignment, you will process an English text (**Lab1-apple-samsung-example.txt**) with both NLTK and spaCy and discuss the similarities and differences."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Who to contact for questions\n",
    "* Piek Vossen (piek.vossen@vu.nl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tip: how to read a file from disk\n",
    "Let's open the file **Lab1-apple-samsung-example.txt** from disk. It should be located in the same folder as this notebook. The most simple way is to specify the full path to the file, e.g.:\n",
    "\n",
    "```\n",
    "path_to_file='/Users/piek/Desktop/HLT-2019/hlt-ma-labs/lab1.toolkits/Lab1-apple-samsung-example.txt'\n",
    "```\n",
    "\n",
    "This will work for me but not for you as it is unlikely that the file has the same path on your machine.\n",
    "\n",
    "We can use the Path module to find the directory of this notebook. Once we have that, we only need to concatenate the name of the text file to this path. This is how you do this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current directory of this notebook: /Users/piek/Desktop/HLT-2019/hlt-ma-labs/lab1.toolkits\n",
      "Path to the text file: /Users/piek/Desktop/HLT-2019/hlt-ma-labs/lab1.toolkits/Lab1-apple-samsung-example.txt\n"
     ]
    }
   ],
   "source": [
    "cur_dir = Path().resolve() # this should provide you with the folder in which this notebook is placed\n",
    "print('Current directory of this notebook:', cur_dir)\n",
    "path_to_file = Path.joinpath(cur_dir, 'Lab1-apple-samsung-example.txt')\n",
    "print('Path to the text file:', path_to_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you are unsure whether the path is correct, you can check if the file exist on that location:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "does path exist? -> True\n"
     ]
    }
   ],
   "source": [
    "print('does path exist? ->', Path.exists(path_to_file))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the output from the code cell above states that **does path exist? -> False**, please check that the file **Lab1-apple-samsung-example.txt** is in the same directory as this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can open the file and access it content. Lets read the complete content and ask for it length using the 'len' function, which will tell us how many characters it has:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of characters 1139\n"
     ]
    }
   ],
   "source": [
    "with open(path_to_file) as infile:\n",
    "    text = infile.read()\n",
    "\n",
    "print('number of characters', len(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.telegraph.co.uk/technology/apple/9702716/Apple-Samsung-lawsuit-six-more-products-under-scrutiny.html\n",
      "\n",
      "Documents filed to the San Jose federal court in California on November 23 list six Samsung products running the \"Jelly Bean\" and \"Ice Cream Sandwich\" operating systems, which Apple claims infringe its patents.\n",
      "The six phones and tablets affected are the Galaxy S III, running the new Jelly Bean system, the Galaxy Tab 8.9 Wifi tablet, the Galaxy Tab 2 10.1, Galaxy Rugby Pro and Galaxy S III mini.\n",
      "Apple stated it had “acted quickly and diligently\" in order to \"determine that these newly released products do infringe many of the same claims already asserted by Apple.\"\n",
      "In August, Samsung lost a US patent case to Apple and was ordered to pay its rival $1.05bn (£0.66bn) in damages for copying features of the iPad and iPhone in its Galaxy range of devices. Samsung, which is the world's top mobile phone maker, is appealing the ruling.\n",
      "A similar case in the UK found in Samsung's favour and ordered Apple to publish an apology making clear that the South Korean firm had not copied its iPad when designing its own devices.\n"
     ]
    }
   ],
   "source": [
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now created a string object with the name 'text' that we can use it for the assignment below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [total points: 4] Exercise 1: NLTK\n",
    "In this exercise, we use NLTK to apply **Part-of-speech (POS) tagging**, **Named Entity Recognition (NER)**, and **Constituency parsing**. The following code snippet already performs sentence splitting and tokenization. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences_nltk = sent_tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_per_sentence = [] # this will become a list of lists!!!\n",
    "\n",
    "for sentence_nltk in sentences_nltk:\n",
    "    sent_tokens = word_tokenize(sentence_nltk)\n",
    "    # We append the tokens of this sentence to the result list\n",
    "    tokens_per_sentence.append(sent_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use lists to keep track of the output of the NLP tasks. We can hence inspect the output for each task using the index of the sentence. Lets look at the first sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SENTENCE The six phones and tablets affected are the Galaxy S III, running the new Jelly Bean system, the Galaxy Tab 8.9 Wifi tablet, the Galaxy Tab 2 10.1, Galaxy Rugby Pro and Galaxy S III mini.\n",
      "TOKENS ['The', 'six', 'phones', 'and', 'tablets', 'affected', 'are', 'the', 'Galaxy', 'S', 'III', ',', 'running', 'the', 'new', 'Jelly', 'Bean', 'system', ',', 'the', 'Galaxy', 'Tab', '8.9', 'Wifi', 'tablet', ',', 'the', 'Galaxy', 'Tab', '2', '10.1', ',', 'Galaxy', 'Rugby', 'Pro', 'and', 'Galaxy', 'S', 'III', 'mini', '.']\n"
     ]
    }
   ],
   "source": [
    "sentence_id = 1\n",
    "print('SENTENCE', sentences_nltk[sentence_id])\n",
    "print('TOKENS', tokens_per_sentence[sentence_id])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [point: 1] Exercise 1a: Part-of-speech (POS) tagging\n",
    "Use *nltk.pos_tag* to perform part-of-speech tagging on a single sentence.\n",
    "\n",
    "Use **print** to show the output in the notebook (and hence also in the exported PDF!)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "sentence_id=2\n",
    "sentence_tokens = tokens_per_sentence[sentence_id]\n",
    "pos_tagged_sentence_tokens= [] #put here the call to nltk pos tagger\n",
    "print(pos_tagged_sentence_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Apple', 'NNP'), ('stated', 'VBD'), ('it', 'PRP'), ('had', 'VBD'), ('“', 'NNP'), ('acted', 'VBD'), ('quickly', 'RB'), ('and', 'CC'), ('diligently', 'RB'), (\"''\", \"''\"), ('in', 'IN'), ('order', 'NN'), ('to', 'TO'), ('``', '``'), ('determine', 'VB'), ('that', 'IN'), ('these', 'DT'), ('newly', 'RB'), ('released', 'VBN'), ('products', 'NNS'), ('do', 'VBP'), ('infringe', 'VB'), ('many', 'JJ'), ('of', 'IN'), ('the', 'DT'), ('same', 'JJ'), ('claims', 'NNS'), ('already', 'RB'), ('asserted', 'VBN'), ('by', 'IN'), ('Apple', 'NNP'), ('.', '.'), (\"''\", \"''\")]\n"
     ]
    }
   ],
   "source": [
    "sentence_id=2\n",
    "sentence_tokens = tokens_per_sentence[sentence_id]\n",
    "pos_tagged_sentence_tokens= nltk.pos_tag(sentence_tokens)\n",
    "print(pos_tagged_sentence_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [point: 1] Exercise 1b: Named Entity Recognition (NER)\n",
    "Use *nltk.chunk.ne_chunk* to perform Named Entity Recognition (NER) on each sentence.\n",
    "\n",
    "Use **print** to show the output in the notebook (and hence also in the exported PDF!)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "tokens_pos_tagged_and_named_entities = []\n",
    "print(tokens_pos_tagged_and_named_entities)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  (PERSON Apple/NNP)\n",
      "  stated/VBD\n",
      "  it/PRP\n",
      "  had/VBD\n",
      "  “/NNP\n",
      "  acted/VBD\n",
      "  quickly/RB\n",
      "  and/CC\n",
      "  diligently/RB\n",
      "  ''/''\n",
      "  in/IN\n",
      "  order/NN\n",
      "  to/TO\n",
      "  ``/``\n",
      "  determine/VB\n",
      "  that/IN\n",
      "  these/DT\n",
      "  newly/RB\n",
      "  released/VBN\n",
      "  products/NNS\n",
      "  do/VBP\n",
      "  infringe/VB\n",
      "  many/JJ\n",
      "  of/IN\n",
      "  the/DT\n",
      "  same/JJ\n",
      "  claims/NNS\n",
      "  already/RB\n",
      "  asserted/VBN\n",
      "  by/IN\n",
      "  (PERSON Apple/NNP)\n",
      "  ./.\n",
      "  ''/'')\n"
     ]
    }
   ],
   "source": [
    "from nltk.chunk import ne_chunk\n",
    "\n",
    "tokens_pos_tagged_and_named_entities = ne_chunk(pos_tagged_sentence_tokens)\n",
    "print(tokens_pos_tagged_and_named_entities)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [points: 2] Exercise 1c: Constituency parsing\n",
    "Use the *nltk.RegexpParser* to perform constituency parsing on each sentence.\n",
    "\n",
    "Use **print** to show the output in the notebook (and hence also in the exported PDF!)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "constituent_parser_v1 = nltk.RegexpParser('''\n",
    "NP: {<DT>? <JJ>* <NN>*} # NP\n",
    "P: {<IN>}           # Preposition\n",
    "V: {<V.*>}          # Verb\n",
    "PP: {<P> <NP>}      # PP -> P NP\n",
    "VP: {<V> <NP|PP>*}  # VP -> V (NP|PP)*''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "constituency_output_for_sentence = []\n",
    "#add here your code to assign the output of the parser 'constituent_parser_v1' to the variable name 'constituent_parser_v1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "print(constituency_output_for_sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Augment the RegexpParser so that it also detects Named Entity Phrases (NEP), e.g., that it detects phrases such as *Galaxy S III* and *Ice Cream Sandwich* as entity phrases, which we give the label 'NEP'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "constituent_parser_v2 = nltk.RegexpParser('''\n",
    "NP: {<DT>? <JJ>* <NN>*} # NP\n",
    "P: {<IN>}           # Preposition\n",
    "V: {<V.*>}          # Verb\n",
    "PP: {<P> <NP>}      # PP -> P NP\n",
    "VP: {<V> <NP|PP>*}  # VP -> V (NP|PP)*\n",
    "NEP: {}             # ???''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "constituent_parser_v2 = nltk.RegexpParser('''\n",
    "NP: {<DT>? <JJ>* <NN>*} # NP\n",
    "P: {<IN>}           # Preposition \n",
    "V: {<V.*>}          # Verb\n",
    "PP: {<P> <NP>}      # PP -> P NP\n",
    "VP: {<V> <NP|PP>*}  # VP -> V (NP|PP)*\n",
    "NEP: {<NNP> *}    # NEP''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "constituency_v2_output_per_sentence = []\n",
    "constituency_v2_output_per_sentence = constituent_parser_v2.parse(pos_tagged_sentence_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'constituency_v2_output_per_sentence' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-07ac1b7d26c0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconstituency_v2_output_per_sentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'constituency_v2_output_per_sentence' is not defined"
     ]
    }
   ],
   "source": [
    "print(constituency_v2_output_per_sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [total points: 1] Exercise 2: spaCy\n",
    "Use Spacy to process the same text as you analyzed with NLTK."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(text) # insert code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tip**: You can use **sents = list(doc.sents)** to be able to use the index to access a sentence like **sents[2]** for the third sentence. Use the previsouly defined \"sentence_id\" to get the output for the same NLTK sentence. Note that we assume that the sentences are split in the same way."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [total points: 5] Exercise 3: Comparison NLTK and spaCy\n",
    "We will now compare the output of NLTK and spaCy. Take the same sentence that you just processed with the NLTK and check the spaCy output for that sentence, i.e. in what do they differ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [points: 2] Exercise 3a: Part of speech tagging\n",
    "Compare the output from NLTK and Spacy regarding part of speech tagging for the same sentence selected before. You already had the PoS Tags from NLTK. Get the tokens and their PoS tags (**token.tag**) from spaCy. Print both and describe any differences. This is not a trick question, it is possible that there are no differences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apple stated it had “acted quickly and diligently\" in order to \"determine that these newly released products do infringe many of the same claims already asserted by Apple.\n"
     ]
    }
   ],
   "source": [
    "sentence=sents[sentence_id]\n",
    "print(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apple\n",
      "Apple\n",
      "[Apple, Apple]\n"
     ]
    }
   ],
   "source": [
    "for ent in sentence.ents:\n",
    "    print(ent)\n",
    "print(sentence.ents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SENTENCE: 0\n",
      "NLTK https://www.telegraph.co.uk/technology/apple/9702716/Apple-Samsung-lawsuit-six-more-products-under-scrutiny.html\n",
      "\n",
      "Documents filed to the San Jose federal court in California on November 23 list six Samsung products running the \"Jelly Bean\" and \"Ice Cream Sandwich\" operating systems, which Apple claims infringe its patents.\n",
      "\n",
      "SpaCy https://www.telegraph.co.uk/technology/apple/9702716/Apple-Samsung-lawsuit-six-more-products-under-scrutiny.html\n",
      "\n",
      "Documents filed to the San Jose federal court in California on November 23 list six Samsung products running the \"Jelly Bean\" and \"Ice Cream Sandwich\" operating systems, which Apple claims infringe its patents.\n",
      "\n",
      "\n",
      "\n",
      "SENTENCE: 1\n",
      "NLTK The six phones and tablets affected are the Galaxy S III, running the new Jelly Bean system, the Galaxy Tab 8.9 Wifi tablet, the Galaxy Tab 2 10.1, Galaxy Rugby Pro and Galaxy S III mini.\n",
      "\n",
      "SpaCy The six phones and tablets affected are the Galaxy S III, running the new Jelly Bean system, the Galaxy Tab 8.9 Wifi tablet, the Galaxy Tab 2 10.1, Galaxy Rugby Pro and Galaxy S III mini.\n",
      "\n",
      "\n",
      "\n",
      "SENTENCE: 2\n",
      "NLTK Apple stated it had “acted quickly and diligently\" in order to \"determine that these newly released products do infringe many of the same claims already asserted by Apple.\"\n",
      "\n",
      "SpaCy Apple stated it had “acted quickly and diligently\" in order to \"determine that these newly released products do infringe many of the same claims already asserted by Apple.\n",
      "\n",
      "\n",
      "SENTENCE: 3\n",
      "NLTK In August, Samsung lost a US patent case to Apple and was ordered to pay its rival $1.05bn (£0.66bn) in damages for copying features of the iPad and iPhone in its Galaxy range of devices.\n",
      "\n",
      "SpaCy \"\n",
      "\n",
      "\n",
      "\n",
      "SENTENCE: 4\n",
      "NLTK Samsung, which is the world's top mobile phone maker, is appealing the ruling.\n",
      "\n",
      "SpaCy In August, Samsung lost a US patent case to Apple and was ordered to pay its rival $1.05bn (£0.66bn) in damages for copying features of the iPad and iPhone in its Galaxy range of devices.\n",
      "\n",
      "\n",
      "SENTENCE: 5\n",
      "NLTK A similar case in the UK found in Samsung's favour and ordered Apple to publish an apology making clear that the South Korean firm had not copied its iPad when designing its own devices.\n",
      "\n",
      "SpaCy Samsung, which is the world's top mobile phone maker, is appealing the ruling.\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sents = list(doc.sents)\n",
    "for i, sentence_nltk in enumerate(sentences_nltk):\n",
    "    print('SENTENCE:', i)\n",
    "    print('NLTK', sentence_nltk)\n",
    "    print()\n",
    "    print('SpaCy', sents[i])\n",
    "    print()\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NLTK TOKENS: ['Apple', 'stated', 'it', 'had', '“', 'acted', 'quickly', 'and', 'diligently', \"''\", 'in', 'order', 'to', '``', 'determine', 'that', 'these', 'newly', 'released', 'products', 'do', 'infringe', 'many', 'of', 'the', 'same', 'claims', 'already', 'asserted', 'by', 'Apple', '.', \"''\"]\n",
      "SPACY TOKENS: Apple stated it had “acted quickly and diligently\" in order to \"determine that these newly released products do infringe many of the same claims already asserted by Apple.\n"
     ]
    }
   ],
   "source": [
    "print('NLTK TOKENS:', sentence_tokens)\n",
    "spacy_tokens=sents[sentence_id]\n",
    "print('SPACY TOKENS:', spacy_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NLTK: ('Apple', 'NNP') SPACY: Apple NNP\n",
      "NLTK: ('stated', 'VBD') SPACY: stated VBD\n",
      "NLTK: ('it', 'PRP') SPACY: it PRP\n",
      "NLTK: ('had', 'VBD') SPACY: had VBD\n",
      "NLTK: ('“', 'NNP') SPACY: “ ``\n",
      "NLTK: ('acted', 'VBD') SPACY: acted VBN\n",
      "NLTK: ('quickly', 'RB') SPACY: quickly RB\n",
      "NLTK: ('and', 'CC') SPACY: and CC\n",
      "NLTK: ('diligently', 'RB') SPACY: diligently RB\n",
      "NLTK: (\"''\", \"''\") SPACY: \" ``\n",
      "NLTK: ('in', 'IN') SPACY: in IN\n",
      "NLTK: ('order', 'NN') SPACY: order NN\n",
      "NLTK: ('to', 'TO') SPACY: to TO\n",
      "NLTK: ('``', '``') SPACY: \" ``\n",
      "NLTK: ('determine', 'VB') SPACY: determine VB\n",
      "NLTK: ('that', 'IN') SPACY: that IN\n",
      "NLTK: ('these', 'DT') SPACY: these DT\n",
      "NLTK: ('newly', 'RB') SPACY: newly RB\n",
      "NLTK: ('released', 'VBN') SPACY: released VBN\n",
      "NLTK: ('products', 'NNS') SPACY: products NNS\n",
      "NLTK: ('do', 'VBP') SPACY: do VBP\n",
      "NLTK: ('infringe', 'VB') SPACY: infringe VB\n",
      "NLTK: ('many', 'JJ') SPACY: many JJ\n",
      "NLTK: ('of', 'IN') SPACY: of IN\n",
      "NLTK: ('the', 'DT') SPACY: the DT\n",
      "NLTK: ('same', 'JJ') SPACY: same JJ\n",
      "NLTK: ('claims', 'NNS') SPACY: claims NNS\n",
      "NLTK: ('already', 'RB') SPACY: already RB\n",
      "NLTK: ('asserted', 'VBN') SPACY: asserted VBN\n",
      "NLTK: ('by', 'IN') SPACY: by IN\n",
      "NLTK: ('Apple', 'NNP') SPACY: Apple NNP\n",
      "NLTK: ('.', '.') SPACY: . .\n",
      "NLTK: (\"''\", \"''\") SPACY: \" ''\n"
     ]
    }
   ],
   "source": [
    "spacy_tokens=sents[sentence_id]\n",
    "for token_id, nltk_token in enumerate(pos_tagged_sentence_tokens):\n",
    "    spacy_token=spacy_tokens[token_id]\n",
    "    print('NLTK:', nltk_token, 'SPACY:', spacy_token.text, spacy_token.tag_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observation**: Most of the PoS tags are the same between the two modules. There are some differences, for example, they disagree on the kind of verb for 'filed'. Also, 'to' is consistently marked as 'TO' by NLTK, whereas it is marked as 'IN' by SpaCy. 'operating' is noun according to NLTK whereas it is a verb according to SpaCy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [points: 1] Exercise 3b: Named Entity Recognition (NER)\n",
    "* For the same sentence.describe differences between the output from NLTK and spaCy for Named Entity Recognition. Which one do you think performs better?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "NLTK named entity & pos tags: (S\n",
      "  (PERSON Apple/NNP)\n",
      "  stated/VBD\n",
      "  it/PRP\n",
      "  had/VBD\n",
      "  “/NNP\n",
      "  acted/VBD\n",
      "  quickly/RB\n",
      "  and/CC\n",
      "  diligently/RB\n",
      "  ''/''\n",
      "  in/IN\n",
      "  order/NN\n",
      "  to/TO\n",
      "  ``/``\n",
      "  determine/VB\n",
      "  that/IN\n",
      "  these/DT\n",
      "  newly/RB\n",
      "  released/VBN\n",
      "  products/NNS\n",
      "  do/VBP\n",
      "  infringe/VB\n",
      "  many/JJ\n",
      "  of/IN\n",
      "  the/DT\n",
      "  same/JJ\n",
      "  claims/NNS\n",
      "  already/RB\n",
      "  asserted/VBN\n",
      "  by/IN\n",
      "  (PERSON Apple/NNP)\n",
      "  ./.\n",
      "  ''/'')\n",
      "NLTK named entities:\n",
      "Apple PERSON\n",
      "Apple PERSON\n",
      "SPACY named entities:\n",
      "Apple ORG\n",
      "Apple ORG\n"
     ]
    }
   ],
   "source": [
    "print(sentence_id)\n",
    "print('NLTK named entity & pos tags:', tokens_pos_tagged_and_named_entities)\n",
    "\n",
    "print('NLTK named entities:')\n",
    "for chunk in tokens_pos_tagged_and_named_entities:\n",
    "    if hasattr(chunk, 'label'):\n",
    "            ent_type=chunk.label()\n",
    "            ent_mention=' '.join(c[0] for c in chunk)\n",
    "            print(ent_mention, ent_type)\n",
    "            \n",
    "print('SPACY named entities:')\n",
    "for ent in sentence.ents:\n",
    "    print(ent.text, ent.label_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observations:** It seems like SpaCy performs better. NLTK makes some obvious mistakes, such as: 'Apple' is classified as a person, 'UK' as an organization, and 'San Jose' as an organization too. Both mistakenly classify 'iPhone' as an organizationm and 'Galaxy S III' as a person."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [points: 1] Exercise 3c: Constituency/dependency parsing\n",
    "For the same sentence from the text, run constituency parsing using NLTK and dependency parsing using spaCy.\n",
    "* describe briefly the difference between constituency parsing and dependency parsing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "constituent_parser = nltk.RegexpParser('''\n",
    "NP: {<DT>? <JJ>* <NN>*} # NP\n",
    "P: {<IN>}           # Preposition\n",
    "V: {<V.*>}          # Verb\n",
    "PP: {<P> <NP>}      # PP -> P NP\n",
    "VP: {<V> <NP|PP>*}  # VP -> V (NP|PP)*''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "constituent_structure = constituent_parser.parse(pos_tagged_sentence_tokens)\n",
    "constituent_structure.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"85f668b4db024f589816ffcee2864145-0\" class=\"displacy\" width=\"4950\" height=\"662.0\" direction=\"ltr\" style=\"max-width: none; height: 662.0px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"572.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">Apple</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"572.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"225\">stated</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"225\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"572.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"400\">it</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"400\">PRON</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"572.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"575\">had “</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"575\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"572.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"750\">acted</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"750\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"572.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"925\">quickly</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"925\">ADV</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"572.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1100\">and</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1100\">CCONJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"572.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1275\">diligently&quot;</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1275\">ADV</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"572.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1450\">in</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1450\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"572.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1625\">order</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1625\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"572.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1800\">to &quot;</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1800\">PART</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"572.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1975\">determine</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1975\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"572.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"2150\">that</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"2150\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"572.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"2325\">these</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"2325\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"572.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"2500\">newly</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"2500\">ADV</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"572.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"2675\">released</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"2675\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"572.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"2850\">products</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"2850\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"572.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"3025\">do</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"3025\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"572.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"3200\">infringe</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"3200\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"572.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"3375\">many</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"3375\">ADJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"572.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"3550\">of</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"3550\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"572.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"3725\">the</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"3725\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"572.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"3900\">same</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"3900\">ADJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"572.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"4075\">claims</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"4075\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"572.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"4250\">already</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"4250\">ADV</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"572.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"4425\">asserted</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"4425\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"572.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"4600\">by</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"4600\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"572.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"4775\">Apple.</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"4775\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-85f668b4db024f589816ffcee2864145-0-0\" stroke-width=\"2px\" d=\"M70,527.0 C70,439.5 200.0,439.5 200.0,527.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-85f668b4db024f589816ffcee2864145-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M70,529.0 L62,517.0 78,517.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-85f668b4db024f589816ffcee2864145-0-1\" stroke-width=\"2px\" d=\"M420,527.0 C420,352.0 730.0,352.0 730.0,527.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-85f668b4db024f589816ffcee2864145-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M420,529.0 L412,517.0 428,517.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-85f668b4db024f589816ffcee2864145-0-2\" stroke-width=\"2px\" d=\"M595,527.0 C595,439.5 725.0,439.5 725.0,527.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-85f668b4db024f589816ffcee2864145-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">aux</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M595,529.0 L587,517.0 603,517.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-85f668b4db024f589816ffcee2864145-0-3\" stroke-width=\"2px\" d=\"M245,527.0 C245,264.5 735.0,264.5 735.0,527.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-85f668b4db024f589816ffcee2864145-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">ccomp</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M735.0,529.0 L743.0,517.0 727.0,517.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-85f668b4db024f589816ffcee2864145-0-4\" stroke-width=\"2px\" d=\"M770,527.0 C770,439.5 900.0,439.5 900.0,527.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-85f668b4db024f589816ffcee2864145-0-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">advmod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M900.0,529.0 L908.0,517.0 892.0,517.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-85f668b4db024f589816ffcee2864145-0-5\" stroke-width=\"2px\" d=\"M945,527.0 C945,439.5 1075.0,439.5 1075.0,527.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-85f668b4db024f589816ffcee2864145-0-5\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">cc</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1075.0,529.0 L1083.0,517.0 1067.0,517.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-85f668b4db024f589816ffcee2864145-0-6\" stroke-width=\"2px\" d=\"M945,527.0 C945,352.0 1255.0,352.0 1255.0,527.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-85f668b4db024f589816ffcee2864145-0-6\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">conj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1255.0,529.0 L1263.0,517.0 1247.0,517.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-85f668b4db024f589816ffcee2864145-0-7\" stroke-width=\"2px\" d=\"M770,527.0 C770,177.0 1440.0,177.0 1440.0,527.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-85f668b4db024f589816ffcee2864145-0-7\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1440.0,529.0 L1448.0,517.0 1432.0,517.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-85f668b4db024f589816ffcee2864145-0-8\" stroke-width=\"2px\" d=\"M1470,527.0 C1470,439.5 1600.0,439.5 1600.0,527.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-85f668b4db024f589816ffcee2864145-0-8\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1600.0,529.0 L1608.0,517.0 1592.0,517.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-85f668b4db024f589816ffcee2864145-0-9\" stroke-width=\"2px\" d=\"M1820,527.0 C1820,439.5 1950.0,439.5 1950.0,527.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-85f668b4db024f589816ffcee2864145-0-9\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">aux</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1820,529.0 L1812,517.0 1828,517.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-85f668b4db024f589816ffcee2864145-0-10\" stroke-width=\"2px\" d=\"M1645,527.0 C1645,352.0 1955.0,352.0 1955.0,527.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-85f668b4db024f589816ffcee2864145-0-10\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">acl</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1955.0,529.0 L1963.0,517.0 1947.0,517.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-85f668b4db024f589816ffcee2864145-0-11\" stroke-width=\"2px\" d=\"M2170,527.0 C2170,89.5 3195.0,89.5 3195.0,527.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-85f668b4db024f589816ffcee2864145-0-11\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">mark</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M2170,529.0 L2162,517.0 2178,517.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-85f668b4db024f589816ffcee2864145-0-12\" stroke-width=\"2px\" d=\"M2345,527.0 C2345,264.5 2835.0,264.5 2835.0,527.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-85f668b4db024f589816ffcee2864145-0-12\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M2345,529.0 L2337,517.0 2353,517.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-85f668b4db024f589816ffcee2864145-0-13\" stroke-width=\"2px\" d=\"M2520,527.0 C2520,439.5 2650.0,439.5 2650.0,527.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-85f668b4db024f589816ffcee2864145-0-13\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">advmod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M2520,529.0 L2512,517.0 2528,517.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-85f668b4db024f589816ffcee2864145-0-14\" stroke-width=\"2px\" d=\"M2695,527.0 C2695,439.5 2825.0,439.5 2825.0,527.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-85f668b4db024f589816ffcee2864145-0-14\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">amod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M2695,529.0 L2687,517.0 2703,517.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-85f668b4db024f589816ffcee2864145-0-15\" stroke-width=\"2px\" d=\"M2870,527.0 C2870,352.0 3180.0,352.0 3180.0,527.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-85f668b4db024f589816ffcee2864145-0-15\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M2870,529.0 L2862,517.0 2878,517.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-85f668b4db024f589816ffcee2864145-0-16\" stroke-width=\"2px\" d=\"M3045,527.0 C3045,439.5 3175.0,439.5 3175.0,527.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-85f668b4db024f589816ffcee2864145-0-16\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">aux</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M3045,529.0 L3037,517.0 3053,517.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-85f668b4db024f589816ffcee2864145-0-17\" stroke-width=\"2px\" d=\"M1995,527.0 C1995,2.0 3200.0,2.0 3200.0,527.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-85f668b4db024f589816ffcee2864145-0-17\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">ccomp</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M3200.0,529.0 L3208.0,517.0 3192.0,517.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-85f668b4db024f589816ffcee2864145-0-18\" stroke-width=\"2px\" d=\"M3220,527.0 C3220,439.5 3350.0,439.5 3350.0,527.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-85f668b4db024f589816ffcee2864145-0-18\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">dobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M3350.0,529.0 L3358.0,517.0 3342.0,517.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-85f668b4db024f589816ffcee2864145-0-19\" stroke-width=\"2px\" d=\"M3395,527.0 C3395,439.5 3525.0,439.5 3525.0,527.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-85f668b4db024f589816ffcee2864145-0-19\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M3525.0,529.0 L3533.0,517.0 3517.0,517.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-85f668b4db024f589816ffcee2864145-0-20\" stroke-width=\"2px\" d=\"M3745,527.0 C3745,352.0 4055.0,352.0 4055.0,527.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-85f668b4db024f589816ffcee2864145-0-20\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M3745,529.0 L3737,517.0 3753,517.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-85f668b4db024f589816ffcee2864145-0-21\" stroke-width=\"2px\" d=\"M3920,527.0 C3920,439.5 4050.0,439.5 4050.0,527.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-85f668b4db024f589816ffcee2864145-0-21\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">amod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M3920,529.0 L3912,517.0 3928,517.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-85f668b4db024f589816ffcee2864145-0-22\" stroke-width=\"2px\" d=\"M3570,527.0 C3570,264.5 4060.0,264.5 4060.0,527.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-85f668b4db024f589816ffcee2864145-0-22\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M4060.0,529.0 L4068.0,517.0 4052.0,517.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-85f668b4db024f589816ffcee2864145-0-23\" stroke-width=\"2px\" d=\"M4270,527.0 C4270,439.5 4400.0,439.5 4400.0,527.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-85f668b4db024f589816ffcee2864145-0-23\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">advmod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M4270,529.0 L4262,517.0 4278,517.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-85f668b4db024f589816ffcee2864145-0-24\" stroke-width=\"2px\" d=\"M4095,527.0 C4095,352.0 4405.0,352.0 4405.0,527.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-85f668b4db024f589816ffcee2864145-0-24\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">acl</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M4405.0,529.0 L4413.0,517.0 4397.0,517.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-85f668b4db024f589816ffcee2864145-0-25\" stroke-width=\"2px\" d=\"M4445,527.0 C4445,439.5 4575.0,439.5 4575.0,527.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-85f668b4db024f589816ffcee2864145-0-25\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">agent</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M4575.0,529.0 L4583.0,517.0 4567.0,517.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-85f668b4db024f589816ffcee2864145-0-26\" stroke-width=\"2px\" d=\"M4620,527.0 C4620,439.5 4750.0,439.5 4750.0,527.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-85f668b4db024f589816ffcee2864145-0-26\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M4750.0,529.0 L4758.0,517.0 4742.0,517.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from spacy import displacy\n",
    "displacy.render(list(doc.sents)[sentence_id], jupyter=True, style='dep')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:** \n",
    "\n",
    "A constituency parse tree breaks a text into sub-phrases. Non-terminals in the tree are types of phrases, the terminals are the words in the sentence, and the edges are unlabeled.\n",
    "\n",
    "A dependency parse connects words according to their relationships. Each vertex in the tree represents a word, child nodes are words that are dependent on the parent, and edges are labeled by the relationship.\n",
    "\n",
    "There are quite a few differences, some of which stem from the differences in the task definition (constituency vs dependency), and some are decisions that the tools made within the task. For instance, regarding the latter, in SpaCy: 'that', these', etc. are associated with the verb 'infringe'; in NLTK, 'that ' and 'these' form a phrase with each other and group with other words in the higher layers, only merging with the phrase of 'infringe' at the root node."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End of the assignment 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
