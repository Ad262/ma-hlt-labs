{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab2.1: Words, concepts, semantic relations in Wordnet-NLTK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright: Vrije Universiteit Amsterdam, Faculty of Humanities, CLTL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, you are going to work with the famous wordnet databases as they have been incorporated in the NLTK package.\n",
    "Detailed information how to access and use wordnet can be found here: http://www.nltk.org/howto/wordnet.html\n",
    "\n",
    "Study the documentation and make yourself familiar with the different commands. Some of them are repeated below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet as wn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look up a word using the \"wn.synsets()\" function. This will give you a list of synsets in which the lookup string is matched with a lemma (synonym)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of synsets with \"dog\" as a synonym: 8\n",
      "[Synset('dog.n.01'), Synset('frump.n.01'), Synset('dog.n.03'), Synset('cad.n.01'), Synset('frank.n.02'), Synset('pawl.n.01'), Synset('andiron.n.01'), Synset('chase.v.01')]\n"
     ]
    }
   ],
   "source": [
    "all_dog_synsets = wn.synsets('dog')\n",
    "print('Number of synsets with \"dog\" as a synonym:', len(all_dog_synsets))\n",
    "print(all_dog_synsets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the synsets in this list are printed by listing the first synonym only. Also note that we got nouns and verbs. We can iterate over the list to get each synset as an 'object' and next call specific functions for each synset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The synonyms =  [Lemma('dog.n.01.dog'), Lemma('dog.n.01.domestic_dog'), Lemma('dog.n.01.Canis_familiaris')]\n",
      "The definition = a member of the genus Canis (probably descended from the common wolf) that has been domesticated by man since prehistoric times; occurs in many breeds\n",
      "The full path of hypernyms = [[Synset('entity.n.01'), Synset('physical_entity.n.01'), Synset('object.n.01'), Synset('whole.n.02'), Synset('living_thing.n.01'), Synset('organism.n.01'), Synset('animal.n.01'), Synset('chordate.n.01'), Synset('vertebrate.n.01'), Synset('mammal.n.01'), Synset('placental.n.01'), Synset('carnivore.n.01'), Synset('canine.n.02'), Synset('dog.n.01')], [Synset('entity.n.01'), Synset('physical_entity.n.01'), Synset('object.n.01'), Synset('whole.n.02'), Synset('living_thing.n.01'), Synset('organism.n.01'), Synset('animal.n.01'), Synset('domestic_animal.n.01'), Synset('dog.n.01')]]\n",
      "The maximum depth of its hyponymy chain is =  13\n",
      "\n",
      "The synonyms =  [Lemma('frump.n.01.frump'), Lemma('frump.n.01.dog')]\n",
      "The definition = a dull unattractive unpleasant girl or woman\n",
      "The full path of hypernyms = [[Synset('entity.n.01'), Synset('physical_entity.n.01'), Synset('causal_agent.n.01'), Synset('person.n.01'), Synset('unwelcome_person.n.01'), Synset('unpleasant_person.n.01'), Synset('unpleasant_woman.n.01'), Synset('frump.n.01')], [Synset('entity.n.01'), Synset('physical_entity.n.01'), Synset('object.n.01'), Synset('whole.n.02'), Synset('living_thing.n.01'), Synset('organism.n.01'), Synset('person.n.01'), Synset('unwelcome_person.n.01'), Synset('unpleasant_person.n.01'), Synset('unpleasant_woman.n.01'), Synset('frump.n.01')]]\n",
      "The maximum depth of its hyponymy chain is =  10\n",
      "\n",
      "The synonyms =  [Lemma('dog.n.03.dog')]\n",
      "The definition = informal term for a man\n",
      "The full path of hypernyms = [[Synset('entity.n.01'), Synset('physical_entity.n.01'), Synset('causal_agent.n.01'), Synset('person.n.01'), Synset('male.n.02'), Synset('chap.n.01'), Synset('dog.n.03')], [Synset('entity.n.01'), Synset('physical_entity.n.01'), Synset('object.n.01'), Synset('whole.n.02'), Synset('living_thing.n.01'), Synset('organism.n.01'), Synset('person.n.01'), Synset('male.n.02'), Synset('chap.n.01'), Synset('dog.n.03')]]\n",
      "The maximum depth of its hyponymy chain is =  9\n",
      "\n",
      "The synonyms =  [Lemma('cad.n.01.cad'), Lemma('cad.n.01.bounder'), Lemma('cad.n.01.blackguard'), Lemma('cad.n.01.dog'), Lemma('cad.n.01.hound'), Lemma('cad.n.01.heel')]\n",
      "The definition = someone who is morally reprehensible\n",
      "The full path of hypernyms = [[Synset('entity.n.01'), Synset('physical_entity.n.01'), Synset('causal_agent.n.01'), Synset('person.n.01'), Synset('unwelcome_person.n.01'), Synset('villain.n.01'), Synset('cad.n.01')], [Synset('entity.n.01'), Synset('physical_entity.n.01'), Synset('object.n.01'), Synset('whole.n.02'), Synset('living_thing.n.01'), Synset('organism.n.01'), Synset('person.n.01'), Synset('unwelcome_person.n.01'), Synset('villain.n.01'), Synset('cad.n.01')]]\n",
      "The maximum depth of its hyponymy chain is =  9\n",
      "\n",
      "The synonyms =  [Lemma('frank.n.02.frank'), Lemma('frank.n.02.frankfurter'), Lemma('frank.n.02.hotdog'), Lemma('frank.n.02.hot_dog'), Lemma('frank.n.02.dog'), Lemma('frank.n.02.wiener'), Lemma('frank.n.02.wienerwurst'), Lemma('frank.n.02.weenie')]\n",
      "The definition = a smooth-textured sausage of minced beef or pork usually smoked; often served on a bread roll\n",
      "The full path of hypernyms = [[Synset('entity.n.01'), Synset('physical_entity.n.01'), Synset('matter.n.03'), Synset('solid.n.01'), Synset('food.n.02'), Synset('meat.n.01'), Synset('sausage.n.01'), Synset('frank.n.02')]]\n",
      "The maximum depth of its hyponymy chain is =  7\n",
      "\n",
      "The synonyms =  [Lemma('pawl.n.01.pawl'), Lemma('pawl.n.01.detent'), Lemma('pawl.n.01.click'), Lemma('pawl.n.01.dog')]\n",
      "The definition = a hinged catch that fits into a notch of a ratchet to move a wheel forward or prevent it from moving backward\n",
      "The full path of hypernyms = [[Synset('entity.n.01'), Synset('physical_entity.n.01'), Synset('object.n.01'), Synset('whole.n.02'), Synset('artifact.n.01'), Synset('instrumentality.n.03'), Synset('device.n.01'), Synset('restraint.n.06'), Synset('catch.n.06'), Synset('pawl.n.01')]]\n",
      "The maximum depth of its hyponymy chain is =  9\n",
      "\n",
      "The synonyms =  [Lemma('andiron.n.01.andiron'), Lemma('andiron.n.01.firedog'), Lemma('andiron.n.01.dog'), Lemma('andiron.n.01.dog-iron')]\n",
      "The definition = metal supports for logs in a fireplace\n",
      "The full path of hypernyms = [[Synset('entity.n.01'), Synset('physical_entity.n.01'), Synset('object.n.01'), Synset('whole.n.02'), Synset('artifact.n.01'), Synset('instrumentality.n.03'), Synset('device.n.01'), Synset('support.n.10'), Synset('andiron.n.01')]]\n",
      "The maximum depth of its hyponymy chain is =  8\n",
      "\n",
      "The synonyms =  [Lemma('chase.v.01.chase'), Lemma('chase.v.01.chase_after'), Lemma('chase.v.01.trail'), Lemma('chase.v.01.tail'), Lemma('chase.v.01.tag'), Lemma('chase.v.01.give_chase'), Lemma('chase.v.01.dog'), Lemma('chase.v.01.go_after'), Lemma('chase.v.01.track')]\n",
      "The definition = go after with the intent to catch\n",
      "The full path of hypernyms = [[Synset('travel.v.01'), Synset('pursue.v.02'), Synset('chase.v.01')]]\n",
      "The maximum depth of its hyponymy chain is =  2\n"
     ]
    }
   ],
   "source": [
    "for synset in all_dog_synsets:\n",
    "    print()\n",
    "    print('The synonyms = ', synset.lemmas())\n",
    "    print('The definition =', synset.definition())\n",
    "    print('The full path of hypernyms =', synset.hypernym_paths())\n",
    "    print('The maximum depth of its hyponymy chain is = ', synset.max_depth())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also obtain only synsets with a certain part-of-speech."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Synset('chase.v.01')]\n"
     ]
    }
   ],
   "source": [
    "all_dog_verb_synsets = wn.synsets('dog', 'v')\n",
    "print(all_dog_verb_synsets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Various functions can be called on the synset object and data structure can be obtained. Try some to get a feeling for it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Part holonyms: []\n",
      "Member holonyms: [Synset('canis.n.01'), Synset('pack.n.06')]\n",
      "Substance holonyms: []\n",
      "Part meronyms: [Synset('flag.n.07')]\n",
      "Member meronyms: []\n",
      "Substance meronyms: []\n"
     ]
    }
   ],
   "source": [
    "doggy_synset = all_dog_synsets[0]\n",
    "print('Part holonyms:',doggy_synset.part_holonyms())\n",
    "print('Member holonyms:',doggy_synset.member_holonyms())\n",
    "print('Substance holonyms:',doggy_synset.substance_holonyms())\n",
    "\n",
    "print('Part meronyms:',doggy_synset.part_meronyms())\n",
    "print('Member meronyms:',doggy_synset.member_meronyms())\n",
    "print('Substance meronyms:',doggy_synset.substance_meronyms())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Caused: []\n",
      "Entailments: []\n",
      "Hyponyms: [Synset('hound.v.01'), Synset('quest.v.02'), Synset('run_down.v.07'), Synset('tree.v.03')]\n",
      "Examples: ['The policeman chased the mugger down the alley', 'the dog chased the rabbit']\n"
     ]
    }
   ],
   "source": [
    "chase_synset = all_dog_verb_synsets[0]\n",
    "print('Caused:', chase_synset.causes())\n",
    "print('Entailments:',chase_synset.entailments())\n",
    "print('Hyponyms:', chase_synset.hyponyms())\n",
    "print('Examples:', chase_synset.examples())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get the full Python object definition of a synset to show all options, you can use the 'dir' command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir(chase_synset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wordnets in other languages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are wordnets in many different languages and many are linked to the English. The ones that are freely available in the Open Multilingual Wordnet platform: http://compling.hss.ntu.edu.sg/omw/ are also available in NLTK. You can use \"wn.langs\" to get the full list."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You might get an error regarding NLTK not finding a 'omw' dataset. You can download it just like you did in lab1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import nltk\n",
    "# nltk.download('omw')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['als',\n",
       " 'arb',\n",
       " 'bul',\n",
       " 'cat',\n",
       " 'cmn',\n",
       " 'dan',\n",
       " 'ell',\n",
       " 'eng',\n",
       " 'eus',\n",
       " 'fas',\n",
       " 'fin',\n",
       " 'fra',\n",
       " 'glg',\n",
       " 'heb',\n",
       " 'hrv',\n",
       " 'ind',\n",
       " 'ita',\n",
       " 'jpn',\n",
       " 'nld',\n",
       " 'nno',\n",
       " 'nob',\n",
       " 'pol',\n",
       " 'por',\n",
       " 'qcn',\n",
       " 'slv',\n",
       " 'spa',\n",
       " 'swe',\n",
       " 'tha',\n",
       " 'zsm']"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(wn.langs())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The listed language wordnets are created by translating the English synsets (the so-called Expand Method (Vossen (ed.) 1998). This means that the concepts of the English wordnet are re-used and the synonyms in the synsets are translated.\n",
    "\n",
    "Since the concept structure is the same for all these wordnets (they share the English concepts), you can  ask for the language lemmas linked to any synset in English."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Are there any Japanese lemmas linked to English dog sense 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['イヌ', 'ドッグ', '洋犬', '犬', '飼犬', '飼い犬']"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Are there any Japanese lemmas linked to English dog sense 1\n",
    "wn.synset('dog.n.01').lemma_names('jpn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hond', 'joekel']"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The same for Dutch\n",
    "wn.synset('dog.n.01').lemma_names('nld')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wn.synsets('dog.n.01.hond')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfortunately, you cannot directly get the synsets in Wordnet through the same interface we have used before for 'dog'. The next call does not work:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of synsets with \"hond\" as a synonym: 0\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "all_dog_synsets = wn.synsets('hond')\n",
    "print('Number of synsets with \"hond\" as a synonym:', len(all_dog_synsets))\n",
    "print(all_dog_synsets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have to go through the wn.lemmas() function to get the list of lemma objects: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Lemma('dog.n.01.hond'), Lemma('asshole.n.01.hond')]\n"
     ]
    }
   ],
   "source": [
    "dutch_dog_lemmas = wn.lemmas('hond', lang='nld')\n",
    "print(dutch_dog_lemmas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lemma is yet another object with attributes and functions, some of which overlap with those of a synset. Let's check them out through 'dir'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dutch_lemma = dutch_dog_lemmas[0]\n",
    "dir(dutch_lemma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some are different from synset such as lang(). Through .synset() we can go to the synset through the lemma. Obviously, the synset information is the same as for the English wordnet because the Open Dutch Wordnet: http://wordpress.let.vupr.nl/odwn/ was created by expanding the English wordnet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nld\n",
      "[Synset('canine.n.02'), Synset('domestic_animal.n.01')]\n",
      "a member of the genus Canis (probably descended from the common wolf) that has been domesticated by man since prehistoric times; occurs in many breeds\n",
      "[[Synset('entity.n.01'), Synset('physical_entity.n.01'), Synset('object.n.01'), Synset('whole.n.02'), Synset('living_thing.n.01'), Synset('organism.n.01'), Synset('animal.n.01'), Synset('chordate.n.01'), Synset('vertebrate.n.01'), Synset('mammal.n.01'), Synset('placental.n.01'), Synset('carnivore.n.01'), Synset('canine.n.02'), Synset('dog.n.01')], [Synset('entity.n.01'), Synset('physical_entity.n.01'), Synset('object.n.01'), Synset('whole.n.02'), Synset('living_thing.n.01'), Synset('organism.n.01'), Synset('animal.n.01'), Synset('domestic_animal.n.01'), Synset('dog.n.01')]]\n"
     ]
    }
   ],
   "source": [
    "print(dutch_lemma.lang())\n",
    "\n",
    "dutch_dog_synset = dutch_lemma.synset()\n",
    "print(dutch_dog_synset.hypernyms())\n",
    "print(dutch_dog_synset.definition())\n",
    "print(dutch_dog_synset.hypernym_paths())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we have many wordnets in different languages. Can we get statistics in their coverage?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dutch: 36896\n",
      "Italian: 31477\n",
      "Japanese: 64797\n",
      "Slovene: 30898\n"
     ]
    }
   ],
   "source": [
    "print('Dutch:', len(list(wn.all_lemma_names(pos='n', lang='nld'))))\n",
    "print('Italian:', len(list(wn.all_lemma_names(pos='n', lang='ita'))))\n",
    "print('Japanese:', len(list(wn.all_lemma_names(pos='n', lang='jpn'))))\n",
    "print('Slovene:', len(list(wn.all_lemma_names(pos='n', lang='slv'))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the Dutch and Japanese dogs\n",
    "\n",
    "The next simple \"for\" loop iterates over all dog-hyponyms in the English wordnet and prints the synset and any Dutch and Japanese labels. We can easily see, which dogs are 'lexicalized' in which language."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of dogs: 18\n",
      "Synset('basenji.n.01')\n",
      "Dutch: []\n",
      "Japanese: []\n",
      "\n",
      "Synset('corgi.n.01')\n",
      "Dutch: []\n",
      "Japanese: ['ウェルシュ・コーギー']\n",
      "\n",
      "Synset('cur.n.01')\n",
      "Dutch: ['mormel', 'idioot', 'halve_gare', 'bastaard', 'bastaardhond', 'straathond']\n",
      "Japanese: ['雑犬', '雑種犬', '駄犬']\n",
      "\n",
      "Synset('dalmatian.n.02')\n",
      "Dutch: ['dalmatiër', 'Dalmatische']\n",
      "Japanese: []\n",
      "\n",
      "Synset('great_pyrenees.n.01')\n",
      "Dutch: []\n",
      "Japanese: []\n",
      "\n",
      "Synset('griffon.n.02')\n",
      "Dutch: []\n",
      "Japanese: ['グリフォン', 'ブリュッセルグリフォン', 'グリフォンブリュッセロワ']\n",
      "\n",
      "Synset('hunting_dog.n.01')\n",
      "Dutch: []\n",
      "Japanese: ['猟犬']\n",
      "\n",
      "Synset('lapdog.n.01')\n",
      "Dutch: []\n",
      "Japanese: []\n",
      "\n",
      "Synset('leonberg.n.01')\n",
      "Dutch: []\n",
      "Japanese: []\n",
      "\n",
      "Synset('mexican_hairless.n.01')\n",
      "Dutch: []\n",
      "Japanese: []\n",
      "\n",
      "Synset('newfoundland.n.01')\n",
      "Dutch: []\n",
      "Japanese: []\n",
      "\n",
      "Synset('pooch.n.01')\n",
      "Dutch: ['bastaard', 'vuilnisbakkie']\n",
      "Japanese: ['わんこ', 'わんわん', 'わんちゃん']\n",
      "\n",
      "Synset('poodle.n.01')\n",
      "Dutch: ['poedel']\n",
      "Japanese: ['プードル']\n",
      "\n",
      "Synset('pug.n.01')\n",
      "Dutch: ['mops', 'mopshond']\n",
      "Japanese: ['パグ']\n",
      "\n",
      "Synset('puppy.n.01')\n",
      "Dutch: ['hondejong', 'hondenjong', 'pup', 'puppy']\n",
      "Japanese: ['仔犬', '子犬', '小犬', '犬ころ', '犬児', '犬子', '狆ころ']\n",
      "\n",
      "Synset('spitz.n.01')\n",
      "Dutch: []\n",
      "Japanese: []\n",
      "\n",
      "Synset('toy_dog.n.01')\n",
      "Dutch: []\n",
      "Japanese: ['愛玩犬']\n",
      "\n",
      "Synset('working_dog.n.01')\n",
      "Dutch: ['werkhond']\n",
      "Japanese: ['ワーキングドッグ']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dog = wn.synset ('dog.n.01')\n",
    "dogs = dog.hyponyms()\n",
    "print('Number of dogs:', len(dogs))\n",
    "\n",
    "for s in dogs:\n",
    "    print(s)\n",
    "    print('Dutch:', s.lemma_names('nld'))\n",
    "    print('Japanese:', s.lemma_names('jpn'))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This gives dogs as direct hyponyms but maybe there are more dogs as hyponyms of hyponyms of hyponyms, etc.  The WordNet interface documentation uses a so-called anonymous function (lambda) is applied recursively to synsets that are the hyponyms of synsets. This is higher Python magic. For now accept that it traverses the hyponym tree from a starting synset and puts all results in a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hypo = lambda s: s.hyponyms()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of dogs: 189\n"
     ]
    }
   ],
   "source": [
    "dogs_at_all_levels = list(dog.closure(hypo))\n",
    "print('Number of dogs:', len(dogs_at_all_levels))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahhh, we now have 189 dogs instead of 18! Let's check their cverage in Dutch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for s in dogs_at_all_levels: \n",
    "    print(s)\n",
    "    print(s.lemma_names('nld'))\n",
    "    print ()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is clear that the Open Dutch Wordnet lacks coverage compared to the English WordNet. There is work to do to complete it. Perhaps a nice project for you to work on to increase the coverage of the Dutch WordNet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question: are there any Dutch words for Dutch that are not in the English WordNet?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wordnet Similarity\n",
    "\n",
    "A whole series of similarity functions have been built in and can be used for scoring synset pairs. See the documentation for the other methods. We show here how it works for \"path\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dog = wn.synset('dog.n.01')\n",
    "cat = wn.synset('cat.n.01')\n",
    "hit = wn.synset('hit.v.01')\n",
    "slap = wn.synset('slap.v.01')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2\n",
      "0.14285714285714285\n",
      "0.14285714285714285\n"
     ]
    }
   ],
   "source": [
    "print(dog.path_similarity(cat))\n",
    "print(hit.path_similarity(slap))\n",
    "print(wn.path_similarity(hit, slap))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you did some readings on WordNet, you may know that the noun hierarchy has a single top-node synset 'entity-n-01'. All nominal synsets decent from this synset. This is not the case for verbs nor for adjectives. The verb synsets form '559' islands of disconnected synsets with 559 rootnodes. The English WordNet editors decided not to connect these islands in an artificial way as was done for nouns.\n",
    "\n",
    "Let's check this with the NLTK root_hypernyms() function for the above verb synsets 'hit' and 'slap'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root for hit: [Synset('touch.v.01')]\n",
      "Root for hit: [Synset('move.v.02')]\n"
     ]
    }
   ],
   "source": [
    "print('Root for hit:', slap.root_hypernyms())\n",
    "print('Root for hit:', hit.root_hypernyms())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How is it possible to get a value for similarity if the subgraphs are not connected? Well, the package imposes a simulated rootnode by grouping all the subgraph top-nodes under a single node. This is the default setting. If you do not want to use this, you can add a variable to turn it off:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(hit.path_similarity(slap, simulate_root=False))\n",
    "print(wn.path_similarity(hit, slap, simulate_root=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Without the simulated root there is no path from 'hit' to 'slap'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using WordNet similarity for words instead of synsets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now if we want to use this for words, we first need to obtain all the synsets for a word and then compare each synset with the synsets of another word. We thus need a for-loop inside a for-loop. The first loop gets the synsets for the first word and the second loop for each synset the synsets for the second word to compare."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synset('dog.n.01') :\n",
      "\t Synset('cat.n.01') : 0.2\n",
      "\t Synset('guy.n.01') : 0.125\n",
      "\t Synset('cat.n.03') : 0.125\n",
      "\t Synset('kat.n.01') : 0.07692307692307693\n",
      "\t Synset('cat-o'-nine-tails.n.01') : 0.08333333333333333\n",
      "\t Synset('caterpillar.n.02') : 0.07692307692307693\n",
      "\t Synset('big_cat.n.01') : 0.2\n",
      "\t Synset('computerized_tomography.n.01') : 0.05263157894736842\n",
      "Synset('frump.n.01') :\n",
      "\t Synset('cat.n.01') : 0.07142857142857142\n",
      "\t Synset('guy.n.01') : 0.125\n",
      "\t Synset('cat.n.03') : 0.125\n",
      "\t Synset('kat.n.01') : 0.1\n",
      "\t Synset('cat-o'-nine-tails.n.01') : 0.07142857142857142\n",
      "\t Synset('caterpillar.n.02') : 0.06666666666666667\n",
      "\t Synset('big_cat.n.01') : 0.07142857142857142\n",
      "\t Synset('computerized_tomography.n.01') : 0.05555555555555555\n",
      "Synset('dog.n.03') :\n",
      "\t Synset('cat.n.01') : 0.07692307692307693\n",
      "\t Synset('guy.n.01') : 0.2\n",
      "\t Synset('cat.n.03') : 0.14285714285714285\n",
      "\t Synset('kat.n.01') : 0.1111111111111111\n",
      "\t Synset('cat-o'-nine-tails.n.01') : 0.07692307692307693\n",
      "\t Synset('caterpillar.n.02') : 0.07142857142857142\n",
      "\t Synset('big_cat.n.01') : 0.07692307692307693\n",
      "\t Synset('computerized_tomography.n.01') : 0.058823529411764705\n",
      "Synset('cad.n.01') :\n",
      "\t Synset('cat.n.01') : 0.07692307692307693\n",
      "\t Synset('guy.n.01') : 0.14285714285714285\n",
      "\t Synset('cat.n.03') : 0.14285714285714285\n",
      "\t Synset('kat.n.01') : 0.1111111111111111\n",
      "\t Synset('cat-o'-nine-tails.n.01') : 0.07692307692307693\n",
      "\t Synset('caterpillar.n.02') : 0.07142857142857142\n",
      "\t Synset('big_cat.n.01') : 0.07692307692307693\n",
      "\t Synset('computerized_tomography.n.01') : 0.058823529411764705\n",
      "Synset('frank.n.02') :\n",
      "\t Synset('cat.n.01') : 0.05263157894736842\n",
      "\t Synset('guy.n.01') : 0.08333333333333333\n",
      "\t Synset('cat.n.03') : 0.08333333333333333\n",
      "\t Synset('kat.n.01') : 0.09090909090909091\n",
      "\t Synset('cat-o'-nine-tails.n.01') : 0.06666666666666667\n",
      "\t Synset('caterpillar.n.02') : 0.0625\n",
      "\t Synset('big_cat.n.01') : 0.05263157894736842\n",
      "\t Synset('computerized_tomography.n.01') : 0.05555555555555555\n",
      "Synset('pawl.n.01') :\n",
      "\t Synset('cat.n.01') : 0.058823529411764705\n",
      "\t Synset('guy.n.01') : 0.07692307692307693\n",
      "\t Synset('cat.n.03') : 0.07692307692307693\n",
      "\t Synset('kat.n.01') : 0.07142857142857142\n",
      "\t Synset('cat-o'-nine-tails.n.01') : 0.14285714285714285\n",
      "\t Synset('caterpillar.n.02') : 0.1\n",
      "\t Synset('big_cat.n.01') : 0.058823529411764705\n",
      "\t Synset('computerized_tomography.n.01') : 0.05\n",
      "Synset('andiron.n.01') :\n",
      "\t Synset('cat.n.01') : 0.0625\n",
      "\t Synset('guy.n.01') : 0.08333333333333333\n",
      "\t Synset('cat.n.03') : 0.08333333333333333\n",
      "\t Synset('kat.n.01') : 0.07692307692307693\n",
      "\t Synset('cat-o'-nine-tails.n.01') : 0.16666666666666666\n",
      "\t Synset('caterpillar.n.02') : 0.1111111111111111\n",
      "\t Synset('big_cat.n.01') : 0.0625\n",
      "\t Synset('computerized_tomography.n.01') : 0.05263157894736842\n"
     ]
    }
   ],
   "source": [
    "w1='dog'\n",
    "w2='cat'\n",
    "for s1 in wn.synsets(w1, 'n'):\n",
    "    print(s1,':')\n",
    "    for s2 in wn.synsets(w2, 'n'):\n",
    "        print('\\t', s2,':', s1.path_similarity(s2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the highest similarity amond all pairs to find the strongest association "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End of this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
