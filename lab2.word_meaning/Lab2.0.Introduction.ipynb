{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LAB2: Word meaning, similarity and relatedness\n",
    "\n",
    "Copyright, Vrije Universiteit Amsterdam, Faculty of Humanities, CLTL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright: VU University of Amsterdam, Faculty of Humanities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nobody can tell how many words there are in a language nor what different meanings these words have. Nobody knows how to define these meanings correctly either. \n",
    "\n",
    "WordNet is a semantic lexical database that can be seen as a proxy for the words of the English languages with their meanings defined through lexical semantic relations. Wordnets have been built for many other languages, mostly by translating the words from English to this language and copying the meanings over (the so-called expand method). Wordnets can be used to calculate the similarity of word pairs through different techniques. You are going to explore these techniques in this notebook.\n",
    "\n",
    "Word embeddings are vector representations that are derived from large volumes of text. Each word in these corpora is represented through a vector which represents the weights of a hidden layer in  a neural network that learned to predict the context of words. Word embeddings are a powerful resource that can be learned without supervision from text. Whereas wordnets have been built manually on the basis of human intuition, embeddings are derived empirically. It is still to be seen what yields better results: human intuition or sampling of empirical data.\n",
    "\n",
    "In the second LAB of this course, you are going to work with:\n",
    "\n",
    "* Wordnet in English and other languages, as provided in NLTK\n",
    "* Embeddings built from Wikipedia for different languages\n",
    "* Create you own embeddings from text corpora provided by the Leibnitz Corpora Collection for some language\n",
    "* Compare wordnet and embeddings in terms of similarity and relatedness\n",
    "\n",
    "LAB2 contains 5 notebooks, excluding this introduction:\n",
    "\n",
    "* Lab2.1.NLTK_wordnet.ipynb\n",
    "* Lab2.2.NLTK.Wikiepedia2Vec.ipynb\n",
    "* Lab2.3.create_embeddings_in_some_language.ipynb\n",
    "* Lab2.4.Assignment.ipynb\n",
    "* Lab2.5.NLTK.concordances.ipynb\n",
    "\n",
    "You are supposed to work though these notebooks in this order before making the assignment. The final notebook is not necessary for the assignment but nice to see what text-corpus functions are provided in NLTK. \n",
    "\n",
    "Please submit your assignment notebook and a PDF export of the notebook as a Zip file.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End of this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
